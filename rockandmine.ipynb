{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_dataset():\n",
    "    df=pd.read_csv('sonar.csv')\n",
    "    X=df[df.columns[0:60]].values\n",
    "    y=df[df.columns[60]]\n",
    "    \n",
    "    #Encode the dependent variable\n",
    "    encoder=LabelEncoder()\n",
    "    encoder.fit(y)\n",
    "    y=encoder.transform(y)\n",
    "    Y=one_hot_encode(y)\n",
    "    print(X.shape)\n",
    "    return(X,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encode(labels):\n",
    "    n_labels=len(labels)\n",
    "    n_unique_labels=len(np.unique(labels))\n",
    "    one_hot_encode=np.zeros((n_labels,n_unique_labels))\n",
    "    one_hot_encode[np.arange(n_labels),labels]=1\n",
    "    return one_hot_encode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(207, 60)\n"
     ]
    }
   ],
   "source": [
    "X,Y=read_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X,Y=shuffle(X,Y,random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(165, 60)\n",
      "(165, 2)\n",
      "(42, 60)\n"
     ]
    }
   ],
   "source": [
    "train_x,test_x,train_y,test_y=train_test_split(X,Y,test_size=0.20,random_state=415)\n",
    "#Inspect the shape of training and testing\n",
    "print(train_x.shape)\n",
    "print(train_y.shape)\n",
    "print(test_x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_dim 60\n"
     ]
    }
   ],
   "source": [
    "learning_rate=0.3\n",
    "training_epochs=1000\n",
    "cost_history=[]\n",
    "n_dim=X.shape[1]\n",
    "print(\"n_dim\",n_dim)\n",
    "n_class=2\n",
    "model_path=\"C:\\\\Users\\hp\\Desktop\\\\dl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_hidden_1=60\n",
    "n_hidden_2=60\n",
    "n_hidden_3=60\n",
    "n_hidden_4=60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\hp\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "x=tf.placeholder(tf.float32,[None,n_dim])\n",
    "W=tf.Variable(tf.zeros([n_dim,n_class]))\n",
    "b=tf.Variable(tf.zeros([n_class]))\n",
    "y_=tf.placeholder(tf.float32,[None,n_class])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# # define the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multilayer_perceptron(x,weights,biases):\n",
    "    # Hidden Layer with RELU activation\n",
    "    layer_1=tf.add(tf.matmul(x,weights['h1']),biases['b1'])\n",
    "    layer_1=tf.nn.sigmoid(layer_1)\n",
    "    \n",
    "    # Hidden layer with sigmoid activation\n",
    "    \n",
    "    layer_2=tf.add(tf.matmul(layer_1,weights['h2']),biases['b2'])\n",
    "    layer_2=tf.nn.sigmoid(layer_2)\n",
    "    \n",
    "    layer_3=tf.add(tf.matmul(layer_2,weights['h3']),biases['b3'])\n",
    "    layer_3=tf.nn.sigmoid(layer_3)\n",
    "    \n",
    "    layer_4=tf.add(tf.matmul(layer_3,weights['h4']),biases['b4'])\n",
    "    layer_4=tf.nn.sigmoid(layer_3)\n",
    "    \n",
    "    #Output layer with Linear activation\n",
    "    \n",
    "    out_layer=tf.matmul(layer_4,weights['out'])+biases['out']\n",
    "    return out_layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# #Define the weights and biases for each layer of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights={\n",
    "    'h1':tf.Variable(tf.truncated_normal([n_dim,n_hidden_1])),\n",
    "    'h2':tf.Variable(tf.truncated_normal([n_hidden_1,n_hidden_2])),\n",
    "    'h3':tf.Variable(tf.truncated_normal([n_hidden_2,n_hidden_3])),\n",
    "    'h4':tf.Variable(tf.truncated_normal([n_hidden_3,n_hidden_4])),\n",
    "    'out':tf.Variable(tf.truncated_normal([n_hidden_4,n_class]))\n",
    "}\n",
    "biases={\n",
    "    'b1':tf.Variable(tf.truncated_normal([n_hidden_1])),\n",
    "    'b2':tf.Variable(tf.truncated_normal([n_hidden_2])),\n",
    "    'b3':tf.Variable(tf.truncated_normal([n_hidden_3])),\n",
    "    'b4':tf.Variable(tf.truncated_normal([n_hidden_4])),\n",
    "    'out':tf.Variable(tf.truncated_normal([n_class]))\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# # Initialize all the variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "init=tf.global_variables_initializer()\n",
    "saver=tf.train.Saver()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# #Call the defined model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=multilayer_perceptron(x,weights,biases)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# #Define the cost function and optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-14-3c9a467a24ae>:1: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cost_function=tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=y,labels=y_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_step=tf.train.GradientDescentOptimizer(learning_rate).minimize(cost_function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess=tf.Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess.run(init)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# #Calculate the cost and accuracy for each epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0 - cost: 1.6161852 -MSE: 7.698822659759992 -Train Accuracy: 0.45454547\n",
      "epoch: 1 - cost: 1.8852533 -MSE: 10.098118146185467 -Train Accuracy: 0.54545456\n",
      "epoch: 2 - cost: 1.2458682 -MSE: 6.791965056203958 -Train Accuracy: 0.45454547\n",
      "epoch: 3 - cost: 1.8623728 -MSE: 10.052489821077623 -Train Accuracy: 0.54545456\n",
      "epoch: 4 - cost: 1.2473426 -MSE: 6.863122317383213 -Train Accuracy: 0.45454547\n",
      "epoch: 5 - cost: 1.8522922 -MSE: 10.069201076103278 -Train Accuracy: 0.54545456\n",
      "epoch: 6 - cost: 1.2393364 -MSE: 6.912555293669253 -Train Accuracy: 0.45454547\n",
      "epoch: 7 - cost: 1.8385392 -MSE: 10.068502002623891 -Train Accuracy: 0.54545456\n",
      "epoch: 8 - cost: 1.2346536 -MSE: 6.9694283101100085 -Train Accuracy: 0.45454547\n",
      "epoch: 9 - cost: 1.8260769 -MSE: 10.07283247514256 -Train Accuracy: 0.54545456\n",
      "epoch: 10 - cost: 1.2295841 -MSE: 7.023628979064741 -Train Accuracy: 0.45454547\n",
      "epoch: 11 - cost: 1.8136271 -MSE: 10.075276427997414 -Train Accuracy: 0.54545456\n",
      "epoch: 12 - cost: 1.2252011 -MSE: 7.0766130670888625 -Train Accuracy: 0.45454547\n",
      "epoch: 13 - cost: 1.8017521 -MSE: 10.07783375830049 -Train Accuracy: 0.54545456\n",
      "epoch: 14 - cost: 1.2211391 -MSE: 7.126723893077215 -Train Accuracy: 0.45454547\n",
      "epoch: 15 - cost: 1.7904469 -MSE: 10.080099733442617 -Train Accuracy: 0.54545456\n",
      "epoch: 16 - cost: 1.217423 -MSE: 7.17359433664344 -Train Accuracy: 0.45454547\n",
      "epoch: 17 - cost: 1.7798153 -MSE: 10.082376035365158 -Train Accuracy: 0.54545456\n",
      "epoch: 18 - cost: 1.2139572 -MSE: 7.216887830193553 -Train Accuracy: 0.45454547\n",
      "epoch: 19 - cost: 1.7698649 -MSE: 10.084669999777397 -Train Accuracy: 0.54545456\n",
      "epoch: 20 - cost: 1.2106923 -MSE: 7.25660168024747 -Train Accuracy: 0.45454547\n",
      "epoch: 21 - cost: 1.7605813 -MSE: 10.086977337379333 -Train Accuracy: 0.54545456\n",
      "epoch: 22 - cost: 1.2075846 -MSE: 7.292895967512091 -Train Accuracy: 0.45454547\n",
      "epoch: 23 - cost: 1.751924 -MSE: 10.089240177428362 -Train Accuracy: 0.54545456\n",
      "epoch: 24 - cost: 1.2046062 -MSE: 7.326037624103746 -Train Accuracy: 0.45454547\n",
      "epoch: 25 - cost: 1.7438445 -MSE: 10.091384710371791 -Train Accuracy: 0.54545456\n",
      "epoch: 26 - cost: 1.2017405 -MSE: 7.356335838777581 -Train Accuracy: 0.45454547\n",
      "epoch: 27 - cost: 1.7362926 -MSE: 10.09334914944499 -Train Accuracy: 0.54545456\n",
      "epoch: 28 - cost: 1.198976 -MSE: 7.384108591419915 -Train Accuracy: 0.45454547\n",
      "epoch: 29 - cost: 1.7292199 -MSE: 10.095090003054839 -Train Accuracy: 0.54545456\n",
      "epoch: 30 - cost: 1.1963074 -MSE: 7.409657324280529 -Train Accuracy: 0.45454547\n",
      "epoch: 31 - cost: 1.7225814 -MSE: 10.096579442383751 -Train Accuracy: 0.54545456\n",
      "epoch: 32 - cost: 1.1937299 -MSE: 7.4332577342628845 -Train Accuracy: 0.45454547\n",
      "epoch: 33 - cost: 1.7163343 -MSE: 10.09780031573068 -Train Accuracy: 0.54545456\n",
      "epoch: 34 - cost: 1.1912415 -MSE: 7.4551535233189865 -Train Accuracy: 0.45454547\n",
      "epoch: 35 - cost: 1.7104399 -MSE: 10.098742839012584 -Train Accuracy: 0.54545456\n",
      "epoch: 36 - cost: 1.1888388 -MSE: 7.475548993641946 -Train Accuracy: 0.45454547\n",
      "epoch: 37 - cost: 1.7048582 -MSE: 10.099393508336371 -Train Accuracy: 0.54545456\n",
      "epoch: 38 - cost: 1.1865183 -MSE: 7.4946192720954645 -Train Accuracy: 0.45454547\n",
      "epoch: 39 - cost: 1.6995513 -MSE: 10.09973231619622 -Train Accuracy: 0.54545456\n",
      "epoch: 40 - cost: 1.1842748 -MSE: 7.5125002746688425 -Train Accuracy: 0.45454547\n",
      "epoch: 41 - cost: 1.6944808 -MSE: 10.099723539150752 -Train Accuracy: 0.54545456\n",
      "epoch: 42 - cost: 1.1821011 -MSE: 7.529300238620914 -Train Accuracy: 0.45454547\n",
      "epoch: 43 - cost: 1.6896096 -MSE: 10.099323848052146 -Train Accuracy: 0.54545456\n",
      "epoch: 44 - cost: 1.1799897 -MSE: 7.54509676545959 -Train Accuracy: 0.45454547\n",
      "epoch: 45 - cost: 1.6849003 -MSE: 10.098471476408347 -Train Accuracy: 0.54545456\n",
      "epoch: 46 - cost: 1.1779321 -MSE: 7.559943761193957 -Train Accuracy: 0.45454547\n",
      "epoch: 47 - cost: 1.6803193 -MSE: 10.097098233950046 -Train Accuracy: 0.54545456\n",
      "epoch: 48 - cost: 1.1759183 -MSE: 7.573871686141899 -Train Accuracy: 0.45454547\n",
      "epoch: 49 - cost: 1.6758353 -MSE: 10.095132183649705 -Train Accuracy: 0.54545456\n",
      "epoch: 50 - cost: 1.1739407 -MSE: 7.586901470278432 -Train Accuracy: 0.45454547\n",
      "epoch: 51 - cost: 1.6714203 -MSE: 10.092496674945556 -Train Accuracy: 0.54545456\n",
      "epoch: 52 - cost: 1.1719894 -MSE: 7.599037374560244 -Train Accuracy: 0.45454547\n",
      "epoch: 53 - cost: 1.6670508 -MSE: 10.089122917130968 -Train Accuracy: 0.54545456\n",
      "epoch: 54 - cost: 1.1700587 -MSE: 7.610285137818884 -Train Accuracy: 0.45454547\n",
      "epoch: 55 - cost: 1.6627071 -MSE: 10.084950342302571 -Train Accuracy: 0.54545456\n",
      "epoch: 56 - cost: 1.1681414 -MSE: 7.620641150624191 -Train Accuracy: 0.45454547\n",
      "epoch: 57 - cost: 1.6583731 -MSE: 10.079919768645961 -Train Accuracy: 0.54545456\n",
      "epoch: 58 - cost: 1.1662339 -MSE: 7.63010966173673 -Train Accuracy: 0.45454547\n",
      "epoch: 59 - cost: 1.6540372 -MSE: 10.073994192693982 -Train Accuracy: 0.54545456\n",
      "epoch: 60 - cost: 1.1643327 -MSE: 7.6386945358607035 -Train Accuracy: 0.45454547\n",
      "epoch: 61 - cost: 1.64969 -MSE: 10.067141079806158 -Train Accuracy: 0.54545456\n",
      "epoch: 62 - cost: 1.1624359 -MSE: 7.646407966936896 -Train Accuracy: 0.45454547\n",
      "epoch: 63 - cost: 1.6453251 -MSE: 10.05934558377945 -Train Accuracy: 0.54545456\n",
      "epoch: 64 - cost: 1.1605432 -MSE: 7.653266495265135 -Train Accuracy: 0.45454547\n",
      "epoch: 65 - cost: 1.6409379 -MSE: 10.050606104838492 -Train Accuracy: 0.54545456\n",
      "epoch: 66 - cost: 1.1586547 -MSE: 7.659300954304148 -Train Accuracy: 0.45454547\n",
      "epoch: 67 - cost: 1.6365262 -MSE: 10.040933541951794 -Train Accuracy: 0.54545456\n",
      "epoch: 68 - cost: 1.1567719 -MSE: 7.664546078599781 -Train Accuracy: 0.45454547\n",
      "epoch: 69 - cost: 1.6320891 -MSE: 10.030352592616666 -Train Accuracy: 0.54545456\n",
      "epoch: 70 - cost: 1.1548971 -MSE: 7.669048448283806 -Train Accuracy: 0.45454547\n",
      "epoch: 71 - cost: 1.6276262 -MSE: 10.01889945729429 -Train Accuracy: 0.54545456\n",
      "epoch: 72 - cost: 1.1530335 -MSE: 7.672866738815481 -Train Accuracy: 0.45454547\n",
      "epoch: 73 - cost: 1.6231387 -MSE: 10.006623394557076 -Train Accuracy: 0.54545456\n",
      "epoch: 74 - cost: 1.1511846 -MSE: 7.676066806272383 -Train Accuracy: 0.45454547\n",
      "epoch: 75 - cost: 1.6186283 -MSE: 9.993586432632176 -Train Accuracy: 0.54545456\n",
      "epoch: 76 - cost: 1.1493533 -MSE: 7.678718031297838 -Train Accuracy: 0.45454547\n",
      "epoch: 77 - cost: 1.6140965 -MSE: 9.979852718105617 -Train Accuracy: 0.54545456\n",
      "epoch: 78 - cost: 1.147544 -MSE: 7.680898391228544 -Train Accuracy: 0.45454547\n",
      "epoch: 79 - cost: 1.6095443 -MSE: 9.965495143574334 -Train Accuracy: 0.54545456\n",
      "epoch: 80 - cost: 1.1457597 -MSE: 7.682685707572752 -Train Accuracy: 0.45454547\n",
      "epoch: 81 - cost: 1.6049731 -MSE: 9.950592149617014 -Train Accuracy: 0.54545456\n",
      "epoch: 82 - cost: 1.144003 -MSE: 7.684160371905731 -Train Accuracy: 0.45454547\n",
      "epoch: 83 - cost: 1.6003844 -MSE: 9.935225590773577 -Train Accuracy: 0.54545456\n",
      "epoch: 84 - cost: 1.1422756 -MSE: 7.685400039611326 -Train Accuracy: 0.45454547\n",
      "epoch: 85 - cost: 1.5957782 -MSE: 9.91947672845242 -Train Accuracy: 0.54545456\n",
      "epoch: 86 - cost: 1.1405786 -MSE: 7.686479878982318 -Train Accuracy: 0.45454547\n",
      "epoch: 87 - cost: 1.5911549 -MSE: 9.90342452913355 -Train Accuracy: 0.54545456\n",
      "epoch: 88 - cost: 1.1389109 -MSE: 7.6874623560348265 -Train Accuracy: 0.45454547\n",
      "epoch: 89 - cost: 1.5865136 -MSE: 9.887147008920271 -Train Accuracy: 0.54545456\n",
      "epoch: 90 - cost: 1.1372721 -MSE: 7.6884134533449044 -Train Accuracy: 0.45454547\n",
      "epoch: 91 - cost: 1.5818535 -MSE: 9.870714726446952 -Train Accuracy: 0.54545456\n",
      "epoch: 92 - cost: 1.1356597 -MSE: 7.6893811160280965 -Train Accuracy: 0.45454547\n",
      "epoch: 93 - cost: 1.5771736 -MSE: 9.854195432690606 -Train Accuracy: 0.54545456\n",
      "epoch: 94 - cost: 1.134071 -MSE: 7.690409466855639 -Train Accuracy: 0.45454547\n",
      "epoch: 95 - cost: 1.5724732 -MSE: 9.83765184551061 -Train Accuracy: 0.54545456\n",
      "epoch: 96 - cost: 1.132503 -MSE: 7.691538190338758 -Train Accuracy: 0.45454547\n",
      "epoch: 97 - cost: 1.5677503 -MSE: 9.821137596306059 -Train Accuracy: 0.54545456\n",
      "epoch: 98 - cost: 1.1309522 -MSE: 7.692794200671379 -Train Accuracy: 0.45454547\n",
      "epoch: 99 - cost: 1.563005 -MSE: 9.804699009955021 -Train Accuracy: 0.54545456\n",
      "epoch: 100 - cost: 1.1294153 -MSE: 7.694202270489399 -Train Accuracy: 0.45454547\n",
      "epoch: 101 - cost: 1.5582359 -MSE: 9.788376245671603 -Train Accuracy: 0.54545456\n",
      "epoch: 102 - cost: 1.1278896 -MSE: 7.695778346691446 -Train Accuracy: 0.45454547\n",
      "epoch: 103 - cost: 1.553443 -MSE: 9.772204564137683 -Train Accuracy: 0.54545456\n",
      "epoch: 104 - cost: 1.1263715 -MSE: 7.697538782694933 -Train Accuracy: 0.45454547\n",
      "epoch: 105 - cost: 1.5486258 -MSE: 9.756210615214737 -Train Accuracy: 0.54545456\n",
      "epoch: 106 - cost: 1.1248587 -MSE: 7.699489468825522 -Train Accuracy: 0.45454547\n",
      "epoch: 107 - cost: 1.5437847 -MSE: 9.740416204132424 -Train Accuracy: 0.54545456\n",
      "epoch: 108 - cost: 1.1233487 -MSE: 7.701632539127386 -Train Accuracy: 0.45454547\n",
      "epoch: 109 - cost: 1.5389196 -MSE: 9.72483586456046 -Train Accuracy: 0.54545456\n",
      "epoch: 110 - cost: 1.1218395 -MSE: 7.703973943408422 -Train Accuracy: 0.45454547\n",
      "epoch: 111 - cost: 1.5340314 -MSE: 9.709484061612622 -Train Accuracy: 0.54545456\n",
      "epoch: 112 - cost: 1.1203284 -MSE: 7.706509715799411 -Train Accuracy: 0.45454547\n",
      "epoch: 113 - cost: 1.5291198 -MSE: 9.694364251061838 -Train Accuracy: 0.54545456\n",
      "epoch: 114 - cost: 1.1188151 -MSE: 7.709238320239256 -Train Accuracy: 0.45454547\n",
      "epoch: 115 - cost: 1.5241865 -MSE: 9.679482280096648 -Train Accuracy: 0.54545456\n",
      "epoch: 116 - cost: 1.1172969 -MSE: 7.712150254307816 -Train Accuracy: 0.45454547\n",
      "epoch: 117 - cost: 1.5192317 -MSE: 9.664834670684295 -Train Accuracy: 0.54545456\n",
      "epoch: 118 - cost: 1.115773 -MSE: 7.715239913504761 -Train Accuracy: 0.45454547\n",
      "epoch: 119 - cost: 1.5142564 -MSE: 9.650420653494827 -Train Accuracy: 0.54545456\n",
      "epoch: 120 - cost: 1.1142418 -MSE: 7.718498282589847 -Train Accuracy: 0.45454547\n",
      "epoch: 121 - cost: 1.5092611 -MSE: 9.636234386451553 -Train Accuracy: 0.54545456\n",
      "epoch: 122 - cost: 1.1127027 -MSE: 7.721917754601272 -Train Accuracy: 0.45454547\n",
      "epoch: 123 - cost: 1.5042478 -MSE: 9.622270750005274 -Train Accuracy: 0.54545456\n",
      "epoch: 124 - cost: 1.1111538 -MSE: 7.725481893170829 -Train Accuracy: 0.45454547\n",
      "epoch: 125 - cost: 1.4992166 -MSE: 9.60851963262221 -Train Accuracy: 0.54545456\n",
      "epoch: 126 - cost: 1.1095948 -MSE: 7.7291843796944 -Train Accuracy: 0.45454547\n",
      "epoch: 127 - cost: 1.4941683 -MSE: 9.594970182779027 -Train Accuracy: 0.54545456\n",
      "epoch: 128 - cost: 1.1080245 -MSE: 7.733009415483084 -Train Accuracy: 0.45454547\n",
      "epoch: 129 - cost: 1.4891044 -MSE: 9.581610767676423 -Train Accuracy: 0.54545456\n",
      "epoch: 130 - cost: 1.1064422 -MSE: 7.736948289943227 -Train Accuracy: 0.45454547\n",
      "epoch: 131 - cost: 1.4840255 -MSE: 9.568430515006511 -Train Accuracy: 0.54545456\n",
      "epoch: 132 - cost: 1.1048466 -MSE: 7.740985934170497 -Train Accuracy: 0.45454547\n",
      "epoch: 133 - cost: 1.4789326 -MSE: 9.55541695979648 -Train Accuracy: 0.54545456\n",
      "epoch: 134 - cost: 1.1032374 -MSE: 7.745111685433047 -Train Accuracy: 0.45454547\n",
      "epoch: 135 - cost: 1.473827 -MSE: 9.542560079938015 -Train Accuracy: 0.54545456\n",
      "epoch: 136 - cost: 1.1016138 -MSE: 7.749314545641064 -Train Accuracy: 0.45454547\n",
      "epoch: 137 - cost: 1.4687092 -MSE: 9.529843950722434 -Train Accuracy: 0.54545456\n",
      "epoch: 138 - cost: 1.0999743 -MSE: 7.753581453162913 -Train Accuracy: 0.45454547\n",
      "epoch: 139 - cost: 1.4635795 -MSE: 9.517259307759314 -Train Accuracy: 0.54545456\n",
      "epoch: 140 - cost: 1.0983189 -MSE: 7.7579000722130145 -Train Accuracy: 0.45454547\n",
      "epoch: 141 - cost: 1.4584394 -MSE: 9.504791214079367 -Train Accuracy: 0.54545456\n",
      "epoch: 142 - cost: 1.096647 -MSE: 7.76226437013647 -Train Accuracy: 0.45454547\n",
      "epoch: 143 - cost: 1.4532896 -MSE: 9.492432148574299 -Train Accuracy: 0.54545456\n",
      "epoch: 144 - cost: 1.0949572 -MSE: 7.766660939809094 -Train Accuracy: 0.45454547\n",
      "epoch: 145 - cost: 1.4481295 -MSE: 9.480164222233432 -Train Accuracy: 0.54545456\n",
      "epoch: 146 - cost: 1.0932496 -MSE: 7.771080817403569 -Train Accuracy: 0.45454547\n",
      "epoch: 147 - cost: 1.4429618 -MSE: 9.467984304533694 -Train Accuracy: 0.54545456\n",
      "epoch: 148 - cost: 1.0915228 -MSE: 7.775517216331335 -Train Accuracy: 0.45454547\n",
      "epoch: 149 - cost: 1.4377846 -MSE: 9.455877467731758 -Train Accuracy: 0.54545456\n",
      "epoch: 150 - cost: 1.0897771 -MSE: 7.779961851633045 -Train Accuracy: 0.45454547\n",
      "epoch: 151 - cost: 1.4326 -MSE: 9.443836622293539 -Train Accuracy: 0.54545456\n",
      "epoch: 152 - cost: 1.0880108 -MSE: 7.7844049394734975 -Train Accuracy: 0.45454547\n",
      "epoch: 153 - cost: 1.427408 -MSE: 9.431850460659936 -Train Accuracy: 0.54545456\n",
      "epoch: 154 - cost: 1.0862244 -MSE: 7.788843670655953 -Train Accuracy: 0.45454547\n",
      "epoch: 155 - cost: 1.4222093 -MSE: 9.419917113871946 -Train Accuracy: 0.54545456\n",
      "epoch: 156 - cost: 1.0844164 -MSE: 7.793267585667763 -Train Accuracy: 0.45454547\n",
      "epoch: 157 - cost: 1.4170035 -MSE: 9.408021576542536 -Train Accuracy: 0.54545456\n",
      "epoch: 158 - cost: 1.0825868 -MSE: 7.797673380484928 -Train Accuracy: 0.45454547\n",
      "epoch: 159 - cost: 1.4117916 -MSE: 9.396162589602849 -Train Accuracy: 0.54545456\n",
      "epoch: 160 - cost: 1.0807345 -MSE: 7.802056494379637 -Train Accuracy: 0.45454547\n",
      "epoch: 161 - cost: 1.406573 -MSE: 9.384332318009886 -Train Accuracy: 0.54545456\n",
      "epoch: 162 - cost: 1.0788597 -MSE: 7.806411813105642 -Train Accuracy: 0.45454547\n",
      "epoch: 163 - cost: 1.401349 -MSE: 9.37252607829905 -Train Accuracy: 0.54545456\n",
      "epoch: 164 - cost: 1.0769618 -MSE: 7.810736380591785 -Train Accuracy: 0.45454547\n",
      "epoch: 165 - cost: 1.3961192 -MSE: 9.360740310834458 -Train Accuracy: 0.54545456\n",
      "epoch: 166 - cost: 1.0750395 -MSE: 7.815022821794243 -Train Accuracy: 0.45454547\n",
      "epoch: 167 - cost: 1.3908842 -MSE: 9.348968144060354 -Train Accuracy: 0.54545456\n",
      "epoch: 168 - cost: 1.073093 -MSE: 7.819271308536535 -Train Accuracy: 0.45454547\n",
      "epoch: 169 - cost: 1.3856436 -MSE: 9.337209252126652 -Train Accuracy: 0.54545456\n",
      "epoch: 170 - cost: 1.0711219 -MSE: 7.82347847606493 -Train Accuracy: 0.45454547\n",
      "epoch: 171 - cost: 1.3803985 -MSE: 9.32546135296052 -Train Accuracy: 0.54545456\n",
      "epoch: 172 - cost: 1.0691253 -MSE: 7.827640190394088 -Train Accuracy: 0.45454547\n",
      "epoch: 173 - cost: 1.3751482 -MSE: 9.313720293564842 -Train Accuracy: 0.54545456\n",
      "epoch: 174 - cost: 1.067103 -MSE: 7.831756042899346 -Train Accuracy: 0.45454547\n",
      "epoch: 175 - cost: 1.3698934 -MSE: 9.301983692452215 -Train Accuracy: 0.54545456\n",
      "epoch: 176 - cost: 1.0650547 -MSE: 7.835820904235392 -Train Accuracy: 0.45454547\n",
      "epoch: 177 - cost: 1.3646338 -MSE: 9.290248802525088 -Train Accuracy: 0.54545456\n",
      "epoch: 178 - cost: 1.0629796 -MSE: 7.839834116468616 -Train Accuracy: 0.45454547\n",
      "epoch: 179 - cost: 1.3593702 -MSE: 9.278517445011689 -Train Accuracy: 0.54545456\n",
      "epoch: 180 - cost: 1.0608779 -MSE: 7.84379406903836 -Train Accuracy: 0.45454547\n",
      "epoch: 181 - cost: 1.3541025 -MSE: 9.266787290550107 -Train Accuracy: 0.54545456\n",
      "epoch: 182 - cost: 1.0587493 -MSE: 7.8476983663832485 -Train Accuracy: 0.45454547\n",
      "epoch: 183 - cost: 1.3488302 -MSE: 9.255056090241661 -Train Accuracy: 0.54545456\n",
      "epoch: 184 - cost: 1.056593 -MSE: 7.851547331114368 -Train Accuracy: 0.45454547\n",
      "epoch: 185 - cost: 1.3435547 -MSE: 9.243326631386775 -Train Accuracy: 0.54545456\n",
      "epoch: 186 - cost: 1.054409 -MSE: 7.855336311033189 -Train Accuracy: 0.45454547\n",
      "epoch: 187 - cost: 1.3382753 -MSE: 9.231595907189227 -Train Accuracy: 0.54545456\n",
      "epoch: 188 - cost: 1.0521971 -MSE: 7.859066550553545 -Train Accuracy: 0.45454547\n",
      "epoch: 189 - cost: 1.3329928 -MSE: 9.219865025219683 -Train Accuracy: 0.54545456\n",
      "epoch: 190 - cost: 1.0499567 -MSE: 7.862733180986488 -Train Accuracy: 0.45454547\n",
      "epoch: 191 - cost: 1.3277066 -MSE: 9.208132471383628 -Train Accuracy: 0.54545456\n",
      "epoch: 192 - cost: 1.0476885 -MSE: 7.866338255473871 -Train Accuracy: 0.46666667\n",
      "epoch: 193 - cost: 1.3224176 -MSE: 9.196399289160004 -Train Accuracy: 0.54545456\n",
      "epoch: 194 - cost: 1.0453914 -MSE: 7.869878678015404 -Train Accuracy: 0.46666667\n",
      "epoch: 195 - cost: 1.3171257 -MSE: 9.18466578824015 -Train Accuracy: 0.54545456\n",
      "epoch: 196 - cost: 1.0430654 -MSE: 7.873352640178142 -Train Accuracy: 0.46666667\n",
      "epoch: 197 - cost: 1.3118311 -MSE: 9.172932908144194 -Train Accuracy: 0.54545456\n",
      "epoch: 198 - cost: 1.040711 -MSE: 7.876761304261237 -Train Accuracy: 0.46666667\n",
      "epoch: 199 - cost: 1.3065345 -MSE: 9.161199371892318 -Train Accuracy: 0.54545456\n",
      "epoch: 200 - cost: 1.0383278 -MSE: 7.88010157583681 -Train Accuracy: 0.46666667\n",
      "epoch: 201 - cost: 1.3012356 -MSE: 9.149466729262754 -Train Accuracy: 0.54545456\n",
      "epoch: 202 - cost: 1.0359156 -MSE: 7.883369502208082 -Train Accuracy: 0.47272727\n",
      "epoch: 203 - cost: 1.2959342 -MSE: 9.137733658963851 -Train Accuracy: 0.54545456\n",
      "epoch: 204 - cost: 1.033475 -MSE: 7.886569272234288 -Train Accuracy: 0.47272727\n",
      "epoch: 205 - cost: 1.2906318 -MSE: 9.12600305099858 -Train Accuracy: 0.54545456\n",
      "epoch: 206 - cost: 1.0310053 -MSE: 7.889696339323026 -Train Accuracy: 0.47272727\n",
      "epoch: 207 - cost: 1.285328 -MSE: 9.114273911028834 -Train Accuracy: 0.54545456\n",
      "epoch: 208 - cost: 1.0285072 -MSE: 7.892747894481886 -Train Accuracy: 0.47272727\n",
      "epoch: 209 - cost: 1.2800231 -MSE: 9.10254805755838 -Train Accuracy: 0.54545456\n",
      "epoch: 210 - cost: 1.02598 -MSE: 7.895724844391582 -Train Accuracy: 0.47272727\n",
      "epoch: 211 - cost: 1.2747172 -MSE: 9.090824306311475 -Train Accuracy: 0.54545456\n",
      "epoch: 212 - cost: 1.0234249 -MSE: 7.898628306615561 -Train Accuracy: 0.47272727\n",
      "epoch: 213 - cost: 1.2694111 -MSE: 9.07910223934534 -Train Accuracy: 0.54545456\n",
      "epoch: 214 - cost: 1.020841 -MSE: 7.901452779425889 -Train Accuracy: 0.47272727\n",
      "epoch: 215 - cost: 1.2641047 -MSE: 9.067386248093992 -Train Accuracy: 0.54545456\n",
      "epoch: 216 - cost: 1.0182295 -MSE: 7.904199533632983 -Train Accuracy: 0.47272727\n",
      "epoch: 217 - cost: 1.2587985 -MSE: 9.055675593211813 -Train Accuracy: 0.54545456\n",
      "epoch: 218 - cost: 1.0155896 -MSE: 7.906864864041738 -Train Accuracy: 0.47272727\n",
      "epoch: 219 - cost: 1.2534924 -MSE: 9.043966976932335 -Train Accuracy: 0.54545456\n",
      "epoch: 220 - cost: 1.0129223 -MSE: 7.909450958174527 -Train Accuracy: 0.47878787\n",
      "epoch: 221 - cost: 1.2481874 -MSE: 9.032265841316178 -Train Accuracy: 0.54545456\n",
      "epoch: 222 - cost: 1.0102277 -MSE: 7.911955585459966 -Train Accuracy: 0.47878787\n",
      "epoch: 223 - cost: 1.242884 -MSE: 9.02057119956265 -Train Accuracy: 0.54545456\n",
      "epoch: 224 - cost: 1.007506 -MSE: 7.914375614376011 -Train Accuracy: 0.47878787\n",
      "epoch: 225 - cost: 1.2375817 -MSE: 9.008881569073045 -Train Accuracy: 0.54545456\n",
      "epoch: 226 - cost: 1.0047576 -MSE: 7.916709217138935 -Train Accuracy: 0.47878787\n",
      "epoch: 227 - cost: 1.2322816 -MSE: 8.997198858433615 -Train Accuracy: 0.54545456\n",
      "epoch: 228 - cost: 1.0019833 -MSE: 7.918958099519185 -Train Accuracy: 0.4848485\n",
      "epoch: 229 - cost: 1.2269838 -MSE: 8.985523632508459 -Train Accuracy: 0.54545456\n",
      "epoch: 230 - cost: 0.99918234 -MSE: 7.9211192078316826 -Train Accuracy: 0.4848485\n",
      "epoch: 231 - cost: 1.2216885 -MSE: 8.973857661806367 -Train Accuracy: 0.54545456\n",
      "epoch: 232 - cost: 0.996356 -MSE: 7.923193740946037 -Train Accuracy: 0.4909091\n",
      "epoch: 233 - cost: 1.2163965 -MSE: 8.962201310971679 -Train Accuracy: 0.54545456\n",
      "epoch: 234 - cost: 0.993505 -MSE: 7.925178802120107 -Train Accuracy: 0.4909091\n",
      "epoch: 235 - cost: 1.2111084 -MSE: 8.95055493089823 -Train Accuracy: 0.54545456\n",
      "epoch: 236 - cost: 0.9906291 -MSE: 7.927073197075531 -Train Accuracy: 0.4909091\n",
      "epoch: 237 - cost: 1.2058239 -MSE: 8.938916535639096 -Train Accuracy: 0.54545456\n",
      "epoch: 238 - cost: 0.9877291 -MSE: 7.928878040530465 -Train Accuracy: 0.4909091\n",
      "epoch: 239 - cost: 1.2005441 -MSE: 8.927291100977707 -Train Accuracy: 0.54545456\n",
      "epoch: 240 - cost: 0.9848056 -MSE: 7.930588288973489 -Train Accuracy: 0.4909091\n",
      "epoch: 241 - cost: 1.1952693 -MSE: 8.915676041004733 -Train Accuracy: 0.54545456\n",
      "epoch: 242 - cost: 0.9818588 -MSE: 7.93220631013787 -Train Accuracy: 0.4909091\n",
      "epoch: 243 - cost: 1.1900002 -MSE: 8.90407637770819 -Train Accuracy: 0.54545456\n",
      "epoch: 244 - cost: 0.9788894 -MSE: 7.933732794293126 -Train Accuracy: 0.4969697\n",
      "epoch: 245 - cost: 1.1847366 -MSE: 8.892489394770193 -Train Accuracy: 0.54545456\n",
      "epoch: 246 - cost: 0.97589815 -MSE: 7.935164668617925 -Train Accuracy: 0.4969697\n",
      "epoch: 247 - cost: 1.1794795 -MSE: 8.880917204208522 -Train Accuracy: 0.54545456\n",
      "epoch: 248 - cost: 0.97288525 -MSE: 7.936500905296916 -Train Accuracy: 0.4969697\n",
      "epoch: 249 - cost: 1.174229 -MSE: 8.869360598921503 -Train Accuracy: 0.54545456\n",
      "epoch: 250 - cost: 0.9698517 -MSE: 7.937742921751761 -Train Accuracy: 0.4969697\n",
      "epoch: 251 - cost: 1.168986 -MSE: 8.857821865574468 -Train Accuracy: 0.54545456\n",
      "epoch: 252 - cost: 0.966798 -MSE: 7.938888218989398 -Train Accuracy: 0.4969697\n",
      "epoch: 253 - cost: 1.1637509 -MSE: 8.846299055831935 -Train Accuracy: 0.54545456\n",
      "epoch: 254 - cost: 0.9637245 -MSE: 7.939936974229306 -Train Accuracy: 0.4969697\n",
      "epoch: 255 - cost: 1.1585239 -MSE: 8.834797443478877 -Train Accuracy: 0.54545456\n",
      "epoch: 256 - cost: 0.96063197 -MSE: 7.940890758086401 -Train Accuracy: 0.4969697\n",
      "epoch: 257 - cost: 1.153306 -MSE: 8.823315459540858 -Train Accuracy: 0.54545456\n",
      "epoch: 258 - cost: 0.9575212 -MSE: 7.941748155640121 -Train Accuracy: 0.4969697\n",
      "epoch: 259 - cost: 1.148097 -MSE: 8.81185314395636 -Train Accuracy: 0.54545456\n",
      "epoch: 260 - cost: 0.9543928 -MSE: 7.94250610816173 -Train Accuracy: 0.5030303\n",
      "epoch: 261 - cost: 1.1428983 -MSE: 8.800415264509342 -Train Accuracy: 0.54545456\n",
      "epoch: 262 - cost: 0.9512472 -MSE: 7.943168900519352 -Train Accuracy: 0.5090909\n",
      "epoch: 263 - cost: 1.1377097 -MSE: 8.78900186863568 -Train Accuracy: 0.54545456\n",
      "epoch: 264 - cost: 0.9480856 -MSE: 7.943736562732728 -Train Accuracy: 0.5090909\n",
      "epoch: 265 - cost: 1.1325319 -MSE: 8.777614893172847 -Train Accuracy: 0.54545456\n",
      "epoch: 266 - cost: 0.94490784 -MSE: 7.94420495685725 -Train Accuracy: 0.5090909\n",
      "epoch: 267 - cost: 1.1273657 -MSE: 8.76625429835568 -Train Accuracy: 0.54545456\n",
      "epoch: 268 - cost: 0.9417155 -MSE: 7.944578649225238 -Train Accuracy: 0.5090909\n",
      "epoch: 269 - cost: 1.1222109 -MSE: 8.754921120584944 -Train Accuracy: 0.54545456\n",
      "epoch: 270 - cost: 0.93850875 -MSE: 7.944855870193686 -Train Accuracy: 0.5090909\n",
      "epoch: 271 - cost: 1.1170684 -MSE: 8.74361929785756 -Train Accuracy: 0.54545456\n",
      "epoch: 272 - cost: 0.9352885 -MSE: 7.945038136296962 -Train Accuracy: 0.5090909\n",
      "epoch: 273 - cost: 1.111939 -MSE: 8.732348620342881 -Train Accuracy: 0.54545456\n",
      "epoch: 274 - cost: 0.9320555 -MSE: 7.945127492083078 -Train Accuracy: 0.5212121\n",
      "epoch: 275 - cost: 1.1068228 -MSE: 8.721114144217173 -Train Accuracy: 0.54545456\n",
      "epoch: 276 - cost: 0.92881006 -MSE: 7.945120864176642 -Train Accuracy: 0.5272727\n",
      "epoch: 277 - cost: 1.1017201 -MSE: 8.7099123453595 -Train Accuracy: 0.54545456\n",
      "epoch: 278 - cost: 0.9255533 -MSE: 7.94502173462971 -Train Accuracy: 0.5272727\n",
      "epoch: 279 - cost: 1.0966316 -MSE: 8.698749571918908 -Train Accuracy: 0.54545456\n",
      "epoch: 280 - cost: 0.9222856 -MSE: 7.944830893009365 -Train Accuracy: 0.5272727\n",
      "epoch: 281 - cost: 1.0915577 -MSE: 8.687623968187946 -Train Accuracy: 0.54545456\n",
      "epoch: 282 - cost: 0.9190079 -MSE: 7.944547600375991 -Train Accuracy: 0.53333336\n",
      "epoch: 283 - cost: 1.0864987 -MSE: 8.676538691047735 -Train Accuracy: 0.54545456\n",
      "epoch: 284 - cost: 0.91572064 -MSE: 7.944174601357707 -Train Accuracy: 0.53333336\n",
      "epoch: 285 - cost: 1.0814553 -MSE: 8.665499602170417 -Train Accuracy: 0.54545456\n",
      "epoch: 286 - cost: 0.9124248 -MSE: 7.943714848815271 -Train Accuracy: 0.53333336\n",
      "epoch: 287 - cost: 1.0764273 -MSE: 8.654500975694258 -Train Accuracy: 0.54545456\n",
      "epoch: 288 - cost: 0.9091212 -MSE: 7.943166486563778 -Train Accuracy: 0.53333336\n",
      "epoch: 289 - cost: 1.0714164 -MSE: 8.643552414378334 -Train Accuracy: 0.54545456\n",
      "epoch: 290 - cost: 0.9058102 -MSE: 7.942533874136849 -Train Accuracy: 0.53333336\n",
      "epoch: 291 - cost: 1.0664215 -MSE: 8.63265004367824 -Train Accuracy: 0.54545456\n",
      "epoch: 292 - cost: 0.90249234 -MSE: 7.941814372582275 -Train Accuracy: 0.53333336\n",
      "epoch: 293 - cost: 1.0614433 -MSE: 8.62179788727339 -Train Accuracy: 0.54545456\n",
      "epoch: 294 - cost: 0.8991686 -MSE: 7.9410126074200305 -Train Accuracy: 0.53939396\n",
      "epoch: 295 - cost: 1.0564826 -MSE: 8.610996120832821 -Train Accuracy: 0.55151516\n",
      "epoch: 296 - cost: 0.89583945 -MSE: 7.940126734599845 -Train Accuracy: 0.54545456\n",
      "epoch: 297 - cost: 1.0515393 -MSE: 8.600248057865011 -Train Accuracy: 0.55151516\n",
      "epoch: 298 - cost: 0.8925058 -MSE: 7.939161723513406 -Train Accuracy: 0.54545456\n",
      "epoch: 299 - cost: 1.0466139 -MSE: 8.589554428983156 -Train Accuracy: 0.55151516\n",
      "epoch: 300 - cost: 0.88916785 -MSE: 7.938117335122405 -Train Accuracy: 0.55151516\n",
      "epoch: 301 - cost: 1.0417064 -MSE: 8.578917672874393 -Train Accuracy: 0.55151516\n",
      "epoch: 302 - cost: 0.88582665 -MSE: 7.9369983672745725 -Train Accuracy: 0.55151516\n",
      "epoch: 303 - cost: 1.0368174 -MSE: 8.568340213931418 -Train Accuracy: 0.55151516\n",
      "epoch: 304 - cost: 0.88248247 -MSE: 7.935801861794162 -Train Accuracy: 0.55151516\n",
      "epoch: 305 - cost: 1.0319468 -MSE: 8.557820860900037 -Train Accuracy: 0.55757576\n",
      "epoch: 306 - cost: 0.8791361 -MSE: 7.934531713807583 -Train Accuracy: 0.55151516\n",
      "epoch: 307 - cost: 1.0270948 -MSE: 8.547361589170183 -Train Accuracy: 0.55757576\n",
      "epoch: 308 - cost: 0.8757882 -MSE: 7.933190007601592 -Train Accuracy: 0.55757576\n",
      "epoch: 309 - cost: 1.022262 -MSE: 8.536965532095875 -Train Accuracy: 0.56363636\n",
      "epoch: 310 - cost: 0.8724393 -MSE: 7.931778338216288 -Train Accuracy: 0.55757576\n",
      "epoch: 311 - cost: 1.0174482 -MSE: 8.5266335243472 -Train Accuracy: 0.56363636\n",
      "epoch: 312 - cost: 0.86908966 -MSE: 7.930297091646564 -Train Accuracy: 0.55757576\n",
      "epoch: 313 - cost: 1.0126535 -MSE: 8.516366997693096 -Train Accuracy: 0.56363636\n",
      "epoch: 314 - cost: 0.86573994 -MSE: 7.928748995902393 -Train Accuracy: 0.56363636\n",
      "epoch: 315 - cost: 1.0078782 -MSE: 8.506166004280947 -Train Accuracy: 0.56363636\n",
      "epoch: 316 - cost: 0.86239123 -MSE: 7.927136731355639 -Train Accuracy: 0.56363636\n",
      "epoch: 317 - cost: 1.0031223 -MSE: 8.496032597654578 -Train Accuracy: 0.56363636\n",
      "epoch: 318 - cost: 0.8590433 -MSE: 7.925461692614637 -Train Accuracy: 0.56969696\n",
      "epoch: 319 - cost: 0.9983856 -MSE: 8.485967328977486 -Train Accuracy: 0.56363636\n",
      "epoch: 320 - cost: 0.8556967 -MSE: 7.923724850896029 -Train Accuracy: 0.56969696\n",
      "epoch: 321 - cost: 0.99366856 -MSE: 8.47597034236427 -Train Accuracy: 0.56363636\n",
      "epoch: 322 - cost: 0.8523523 -MSE: 7.921927641293365 -Train Accuracy: 0.56969696\n",
      "epoch: 323 - cost: 0.98897105 -MSE: 8.466043624257548 -Train Accuracy: 0.56363636\n",
      "epoch: 324 - cost: 0.84901005 -MSE: 7.920072429301505 -Train Accuracy: 0.58181816\n",
      "epoch: 325 - cost: 0.98429316 -MSE: 8.456186942238812 -Train Accuracy: 0.56363636\n",
      "epoch: 326 - cost: 0.84567064 -MSE: 7.9181593034456474 -Train Accuracy: 0.58181816\n",
      "epoch: 327 - cost: 0.97963434 -MSE: 8.446401382702778 -Train Accuracy: 0.56363636\n",
      "epoch: 328 - cost: 0.8423346 -MSE: 7.916191844563134 -Train Accuracy: 0.58787876\n",
      "epoch: 329 - cost: 0.9749951 -MSE: 8.436685693992668 -Train Accuracy: 0.56363636\n",
      "epoch: 330 - cost: 0.839002 -MSE: 7.914172565338118 -Train Accuracy: 0.5939394\n",
      "epoch: 331 - cost: 0.97037536 -MSE: 8.427045722483987 -Train Accuracy: 0.56969696\n",
      "epoch: 332 - cost: 0.83567375 -MSE: 7.91210019490289 -Train Accuracy: 0.5939394\n",
      "epoch: 333 - cost: 0.965775 -MSE: 8.417477251724796 -Train Accuracy: 0.56969696\n",
      "epoch: 334 - cost: 0.8323497 -MSE: 7.909977437868816 -Train Accuracy: 0.5939394\n",
      "epoch: 335 - cost: 0.9611934 -MSE: 8.407980226694388 -Train Accuracy: 0.56969696\n",
      "epoch: 336 - cost: 0.82903 -MSE: 7.907806198141233 -Train Accuracy: 0.6\n",
      "epoch: 337 - cost: 0.956631 -MSE: 8.398555888544667 -Train Accuracy: 0.57575756\n",
      "epoch: 338 - cost: 0.8257156 -MSE: 7.905588355322351 -Train Accuracy: 0.6\n",
      "epoch: 339 - cost: 0.95208776 -MSE: 8.389204044243193 -Train Accuracy: 0.58181816\n",
      "epoch: 340 - cost: 0.8224061 -MSE: 7.903322923015615 -Train Accuracy: 0.6\n",
      "epoch: 341 - cost: 0.94756293 -MSE: 8.379924441503706 -Train Accuracy: 0.5939394\n",
      "epoch: 342 - cost: 0.8191024 -MSE: 7.90101347203201 -Train Accuracy: 0.6\n",
      "epoch: 343 - cost: 0.9430569 -MSE: 8.370718592413263 -Train Accuracy: 0.6060606\n",
      "epoch: 344 - cost: 0.8158043 -MSE: 7.898662997163906 -Train Accuracy: 0.6\n",
      "epoch: 345 - cost: 0.93856925 -MSE: 8.361583695187797 -Train Accuracy: 0.6060606\n",
      "epoch: 346 - cost: 0.8125126 -MSE: 7.896268586279968 -Train Accuracy: 0.6060606\n",
      "epoch: 347 - cost: 0.93410015 -MSE: 8.352522885551982 -Train Accuracy: 0.6060606\n",
      "epoch: 348 - cost: 0.80922693 -MSE: 7.893834965617226 -Train Accuracy: 0.6121212\n",
      "epoch: 349 - cost: 0.92964876 -MSE: 8.343531884123152 -Train Accuracy: 0.6060606\n",
      "epoch: 350 - cost: 0.8059475 -MSE: 7.8913605678980465 -Train Accuracy: 0.6121212\n",
      "epoch: 351 - cost: 0.9252153 -MSE: 8.334612659797184 -Train Accuracy: 0.6121212\n",
      "epoch: 352 - cost: 0.8026747 -MSE: 7.88884712345892 -Train Accuracy: 0.6121212\n",
      "epoch: 353 - cost: 0.9207993 -MSE: 8.325764472759309 -Train Accuracy: 0.6181818\n",
      "epoch: 354 - cost: 0.7994089 -MSE: 7.886300253937979 -Train Accuracy: 0.6121212\n",
      "epoch: 355 - cost: 0.91640073 -MSE: 8.316986942129713 -Train Accuracy: 0.6242424\n",
      "epoch: 356 - cost: 0.7961498 -MSE: 7.883713920963135 -Train Accuracy: 0.6121212\n",
      "epoch: 357 - cost: 0.91201913 -MSE: 8.308276581242307 -Train Accuracy: 0.6242424\n",
      "epoch: 358 - cost: 0.79289746 -MSE: 7.881091292667579 -Train Accuracy: 0.6181818\n",
      "epoch: 359 - cost: 0.9076545 -MSE: 8.299635097523883 -Train Accuracy: 0.6242424\n",
      "epoch: 360 - cost: 0.7896525 -MSE: 7.878435743204546 -Train Accuracy: 0.6181818\n",
      "epoch: 361 - cost: 0.90330637 -MSE: 8.291061208476052 -Train Accuracy: 0.6242424\n",
      "epoch: 362 - cost: 0.7864148 -MSE: 7.875745233331379 -Train Accuracy: 0.6181818\n",
      "epoch: 363 - cost: 0.8989748 -MSE: 8.282552953728807 -Train Accuracy: 0.6242424\n",
      "epoch: 364 - cost: 0.78318435 -MSE: 7.873022433667957 -Train Accuracy: 0.6181818\n",
      "epoch: 365 - cost: 0.8946587 -MSE: 8.274110338487246 -Train Accuracy: 0.6242424\n",
      "epoch: 366 - cost: 0.7799614 -MSE: 7.8702671529112775 -Train Accuracy: 0.6181818\n",
      "epoch: 367 - cost: 0.89035875 -MSE: 8.265732231398497 -Train Accuracy: 0.6242424\n",
      "epoch: 368 - cost: 0.7767456 -MSE: 7.867481559444294 -Train Accuracy: 0.6181818\n",
      "epoch: 369 - cost: 0.886074 -MSE: 8.257416279714638 -Train Accuracy: 0.6242424\n",
      "epoch: 370 - cost: 0.773537 -MSE: 7.864661833646138 -Train Accuracy: 0.6181818\n",
      "epoch: 371 - cost: 0.8818042 -MSE: 8.249161928811992 -Train Accuracy: 0.6242424\n",
      "epoch: 372 - cost: 0.77033645 -MSE: 7.861815224291248 -Train Accuracy: 0.6181818\n",
      "epoch: 373 - cost: 0.87754923 -MSE: 8.24096923048892 -Train Accuracy: 0.6242424\n",
      "epoch: 374 - cost: 0.76714313 -MSE: 7.858936692753415 -Train Accuracy: 0.6181818\n",
      "epoch: 375 - cost: 0.8733093 -MSE: 8.232836400020963 -Train Accuracy: 0.630303\n",
      "epoch: 376 - cost: 0.76395726 -MSE: 7.8560300529932405 -Train Accuracy: 0.6242424\n",
      "epoch: 377 - cost: 0.86908346 -MSE: 8.224762288441658 -Train Accuracy: 0.6424242\n",
      "epoch: 378 - cost: 0.760779 -MSE: 7.85309342329377 -Train Accuracy: 0.6242424\n",
      "epoch: 379 - cost: 0.86487156 -MSE: 8.216742771281874 -Train Accuracy: 0.6424242\n",
      "epoch: 380 - cost: 0.75760823 -MSE: 7.850130404851278 -Train Accuracy: 0.630303\n",
      "epoch: 381 - cost: 0.86067337 -MSE: 8.20877942002699 -Train Accuracy: 0.6424242\n",
      "epoch: 382 - cost: 0.75444454 -MSE: 7.847137269404519 -Train Accuracy: 0.630303\n",
      "epoch: 383 - cost: 0.85648793 -MSE: 8.200869124220132 -Train Accuracy: 0.6424242\n",
      "epoch: 384 - cost: 0.7512884 -MSE: 7.844116915558239 -Train Accuracy: 0.630303\n",
      "epoch: 385 - cost: 0.852316 -MSE: 8.193010483789667 -Train Accuracy: 0.6424242\n",
      "epoch: 386 - cost: 0.7481395 -MSE: 7.841069117122158 -Train Accuracy: 0.6363636\n",
      "epoch: 387 - cost: 0.84815663 -MSE: 8.185203276055772 -Train Accuracy: 0.6484848\n",
      "epoch: 388 - cost: 0.74499786 -MSE: 7.837994339772226 -Train Accuracy: 0.6363636\n",
      "epoch: 389 - cost: 0.8440101 -MSE: 8.177445364152526 -Train Accuracy: 0.6545454\n",
      "epoch: 390 - cost: 0.74186367 -MSE: 7.834893153654256 -Train Accuracy: 0.6363636\n",
      "epoch: 391 - cost: 0.83987546 -MSE: 8.169735868929408 -Train Accuracy: 0.6545454\n",
      "epoch: 392 - cost: 0.7387364 -MSE: 7.8317645031934475 -Train Accuracy: 0.6363636\n",
      "epoch: 393 - cost: 0.83575267 -MSE: 8.162071236787844 -Train Accuracy: 0.6606061\n",
      "epoch: 394 - cost: 0.7356163 -MSE: 7.828609606223689 -Train Accuracy: 0.6363636\n",
      "epoch: 395 - cost: 0.8316414 -MSE: 8.154450368844133 -Train Accuracy: 0.6606061\n",
      "epoch: 396 - cost: 0.732503 -MSE: 7.825427328623587 -Train Accuracy: 0.6424242\n",
      "epoch: 397 - cost: 0.82754153 -MSE: 8.14687473349871 -Train Accuracy: 0.6666667\n",
      "epoch: 398 - cost: 0.7293966 -MSE: 7.82221997387389 -Train Accuracy: 0.6424242\n",
      "epoch: 399 - cost: 0.8234526 -MSE: 8.139336935606924 -Train Accuracy: 0.6666667\n",
      "epoch: 400 - cost: 0.72629696 -MSE: 7.818984886038014 -Train Accuracy: 0.6424242\n",
      "epoch: 401 - cost: 0.8193744 -MSE: 8.131839899279996 -Train Accuracy: 0.6666667\n",
      "epoch: 402 - cost: 0.723204 -MSE: 7.815724486995616 -Train Accuracy: 0.6424242\n",
      "epoch: 403 - cost: 0.8153066 -MSE: 8.124379930366784 -Train Accuracy: 0.6666667\n",
      "epoch: 404 - cost: 0.7201176 -MSE: 7.8124371947329925 -Train Accuracy: 0.6424242\n",
      "epoch: 405 - cost: 0.8112491 -MSE: 8.11695736529003 -Train Accuracy: 0.6666667\n",
      "epoch: 406 - cost: 0.71703774 -MSE: 7.8091238078248315 -Train Accuracy: 0.6424242\n",
      "epoch: 407 - cost: 0.80720156 -MSE: 8.109566389386286 -Train Accuracy: 0.6666667\n",
      "epoch: 408 - cost: 0.71396405 -MSE: 7.8057831717640545 -Train Accuracy: 0.6424242\n",
      "epoch: 409 - cost: 0.80316335 -MSE: 8.102209113978661 -Train Accuracy: 0.6666667\n",
      "epoch: 410 - cost: 0.7108966 -MSE: 7.802417225831238 -Train Accuracy: 0.6424242\n",
      "epoch: 411 - cost: 0.7991353 -MSE: 8.094884338348905 -Train Accuracy: 0.6727273\n",
      "epoch: 412 - cost: 0.7078353 -MSE: 7.799025004459211 -Train Accuracy: 0.6424242\n",
      "epoch: 413 - cost: 0.7951159 -MSE: 8.087587750289089 -Train Accuracy: 0.6727273\n",
      "epoch: 414 - cost: 0.7047799 -MSE: 7.795605973293244 -Train Accuracy: 0.6424242\n",
      "epoch: 415 - cost: 0.79110587 -MSE: 8.0803188570808 -Train Accuracy: 0.6727273\n",
      "epoch: 416 - cost: 0.70173085 -MSE: 7.792160447362979 -Train Accuracy: 0.6424242\n",
      "epoch: 417 - cost: 0.7871045 -MSE: 8.073076327772927 -Train Accuracy: 0.6727273\n",
      "epoch: 418 - cost: 0.69868696 -MSE: 7.7886880320364344 -Train Accuracy: 0.6424242\n",
      "epoch: 419 - cost: 0.7831117 -MSE: 8.065858792387749 -Train Accuracy: 0.6727273\n",
      "epoch: 420 - cost: 0.6956488 -MSE: 7.785187715672652 -Train Accuracy: 0.6424242\n",
      "epoch: 421 - cost: 0.77912706 -MSE: 8.058663417525773 -Train Accuracy: 0.6727273\n",
      "epoch: 422 - cost: 0.69261634 -MSE: 7.781662793348395 -Train Accuracy: 0.6424242\n",
      "epoch: 423 - cost: 0.7751507 -MSE: 8.051489287193599 -Train Accuracy: 0.6727273\n",
      "epoch: 424 - cost: 0.689589 -MSE: 7.778110291080679 -Train Accuracy: 0.6424242\n",
      "epoch: 425 - cost: 0.7711822 -MSE: 8.044335730136636 -Train Accuracy: 0.6727273\n",
      "epoch: 426 - cost: 0.6865671 -MSE: 7.774531606264769 -Train Accuracy: 0.6484848\n",
      "epoch: 427 - cost: 0.7672218 -MSE: 8.037199512748137 -Train Accuracy: 0.6727273\n",
      "epoch: 428 - cost: 0.6835503 -MSE: 7.77092315706948 -Train Accuracy: 0.6545454\n",
      "epoch: 429 - cost: 0.7632689 -MSE: 8.030080001184789 -Train Accuracy: 0.6787879\n",
      "epoch: 430 - cost: 0.680539 -MSE: 7.767288882878863 -Train Accuracy: 0.6606061\n",
      "epoch: 431 - cost: 0.7593239 -MSE: 8.02297902811364 -Train Accuracy: 0.6787879\n",
      "epoch: 432 - cost: 0.67753226 -MSE: 7.763630088557799 -Train Accuracy: 0.6666667\n",
      "epoch: 433 - cost: 0.7553859 -MSE: 8.015891722962852 -Train Accuracy: 0.6787879\n",
      "epoch: 434 - cost: 0.6745305 -MSE: 7.75994246270345 -Train Accuracy: 0.6666667\n",
      "epoch: 435 - cost: 0.7514553 -MSE: 8.00881708534899 -Train Accuracy: 0.6787879\n",
      "epoch: 436 - cost: 0.67153347 -MSE: 7.756229787455864 -Train Accuracy: 0.6666667\n",
      "epoch: 437 - cost: 0.747532 -MSE: 8.00175543521255 -Train Accuracy: 0.6787879\n",
      "epoch: 438 - cost: 0.6685412 -MSE: 7.752487413814996 -Train Accuracy: 0.6666667\n",
      "epoch: 439 - cost: 0.7436156 -MSE: 7.9947038750465484 -Train Accuracy: 0.6787879\n",
      "epoch: 440 - cost: 0.66555333 -MSE: 7.7487194378119515 -Train Accuracy: 0.6666667\n",
      "epoch: 441 - cost: 0.73970634 -MSE: 7.987663412986029 -Train Accuracy: 0.6787879\n",
      "epoch: 442 - cost: 0.6625702 -MSE: 7.744924009863175 -Train Accuracy: 0.6727273\n",
      "epoch: 443 - cost: 0.73580384 -MSE: 7.980628764040013 -Train Accuracy: 0.6787879\n",
      "epoch: 444 - cost: 0.6595912 -MSE: 7.741100654893351 -Train Accuracy: 0.6727273\n",
      "epoch: 445 - cost: 0.731908 -MSE: 7.973603019329845 -Train Accuracy: 0.6787879\n",
      "epoch: 446 - cost: 0.6566167 -MSE: 7.73725150432972 -Train Accuracy: 0.6848485\n",
      "epoch: 447 - cost: 0.72801876 -MSE: 7.966583685183819 -Train Accuracy: 0.6787879\n",
      "epoch: 448 - cost: 0.65364623 -MSE: 7.733374635639461 -Train Accuracy: 0.6848485\n",
      "epoch: 449 - cost: 0.7241365 -MSE: 7.959567708807873 -Train Accuracy: 0.6787879\n",
      "epoch: 450 - cost: 0.6506801 -MSE: 7.729469209662518 -Train Accuracy: 0.6848485\n",
      "epoch: 451 - cost: 0.7202608 -MSE: 7.952559046564933 -Train Accuracy: 0.6787879\n",
      "epoch: 452 - cost: 0.64771795 -MSE: 7.725539841798875 -Train Accuracy: 0.6848485\n",
      "epoch: 453 - cost: 0.7163917 -MSE: 7.945553488668672 -Train Accuracy: 0.6848485\n",
      "epoch: 454 - cost: 0.64476 -MSE: 7.721581525815222 -Train Accuracy: 0.6848485\n",
      "epoch: 455 - cost: 0.71252924 -MSE: 7.9385503794680385 -Train Accuracy: 0.6909091\n",
      "epoch: 456 - cost: 0.6418062 -MSE: 7.717597402348092 -Train Accuracy: 0.6909091\n",
      "epoch: 457 - cost: 0.7086737 -MSE: 7.9315503289652485 -Train Accuracy: 0.6909091\n",
      "epoch: 458 - cost: 0.63885623 -MSE: 7.713586324127509 -Train Accuracy: 0.6909091\n",
      "epoch: 459 - cost: 0.7048244 -MSE: 7.924550681188005 -Train Accuracy: 0.6909091\n",
      "epoch: 460 - cost: 0.63591015 -MSE: 7.709546563932145 -Train Accuracy: 0.6909091\n",
      "epoch: 461 - cost: 0.70098174 -MSE: 7.917553797157983 -Train Accuracy: 0.6909091\n",
      "epoch: 462 - cost: 0.63296807 -MSE: 7.705483085616583 -Train Accuracy: 0.6909091\n",
      "epoch: 463 - cost: 0.6971461 -MSE: 7.910555325822977 -Train Accuracy: 0.6909091\n",
      "epoch: 464 - cost: 0.63003 -MSE: 7.701392946174742 -Train Accuracy: 0.6909091\n",
      "epoch: 465 - cost: 0.6933171 -MSE: 7.903557664779454 -Train Accuracy: 0.6909091\n",
      "epoch: 466 - cost: 0.62709564 -MSE: 7.697275261069049 -Train Accuracy: 0.6909091\n",
      "epoch: 467 - cost: 0.6894949 -MSE: 7.89656074016246 -Train Accuracy: 0.6909091\n",
      "epoch: 468 - cost: 0.6241654 -MSE: 7.6931332000537305 -Train Accuracy: 0.6909091\n",
      "epoch: 469 - cost: 0.6856797 -MSE: 7.889563331282677 -Train Accuracy: 0.6909091\n",
      "epoch: 470 - cost: 0.6212389 -MSE: 7.688966157019609 -Train Accuracy: 0.6909091\n",
      "epoch: 471 - cost: 0.68187124 -MSE: 7.8825634515021346 -Train Accuracy: 0.6909091\n",
      "epoch: 472 - cost: 0.6183165 -MSE: 7.684772186703718 -Train Accuracy: 0.6969697\n",
      "epoch: 473 - cost: 0.6780701 -MSE: 7.875563275546028 -Train Accuracy: 0.6969697\n",
      "epoch: 474 - cost: 0.6153976 -MSE: 7.680553528742758 -Train Accuracy: 0.6969697\n",
      "epoch: 475 - cost: 0.6742759 -MSE: 7.8685602779396016 -Train Accuracy: 0.6969697\n",
      "epoch: 476 - cost: 0.61248296 -MSE: 7.6763093275203085 -Train Accuracy: 0.6969697\n",
      "epoch: 477 - cost: 0.6704893 -MSE: 7.861555817066702 -Train Accuracy: 0.7030303\n",
      "epoch: 478 - cost: 0.6095723 -MSE: 7.6720407447311265 -Train Accuracy: 0.6969697\n",
      "epoch: 479 - cost: 0.66671 -MSE: 7.854551548529007 -Train Accuracy: 0.7030303\n",
      "epoch: 480 - cost: 0.6066655 -MSE: 7.66774956491724 -Train Accuracy: 0.6969697\n",
      "epoch: 481 - cost: 0.66293836 -MSE: 7.847545624106213 -Train Accuracy: 0.7030303\n",
      "epoch: 482 - cost: 0.603763 -MSE: 7.66343618839658 -Train Accuracy: 0.7030303\n",
      "epoch: 483 - cost: 0.65917444 -MSE: 7.840537532166523 -Train Accuracy: 0.7030303\n",
      "epoch: 484 - cost: 0.6008646 -MSE: 7.659096789933631 -Train Accuracy: 0.7030303\n",
      "epoch: 485 - cost: 0.65541846 -MSE: 7.833529941659758 -Train Accuracy: 0.7030303\n",
      "epoch: 486 - cost: 0.5979705 -MSE: 7.654734415993511 -Train Accuracy: 0.7090909\n",
      "epoch: 487 - cost: 0.65167063 -MSE: 7.826518625083245 -Train Accuracy: 0.7030303\n",
      "epoch: 488 - cost: 0.59508055 -MSE: 7.650351765107793 -Train Accuracy: 0.7090909\n",
      "epoch: 489 - cost: 0.6479311 -MSE: 7.819509734053619 -Train Accuracy: 0.7030303\n",
      "epoch: 490 - cost: 0.5921949 -MSE: 7.645946831800573 -Train Accuracy: 0.7090909\n",
      "epoch: 491 - cost: 0.64419997 -MSE: 7.812499432828103 -Train Accuracy: 0.7030303\n",
      "epoch: 492 - cost: 0.5893139 -MSE: 7.641519406354705 -Train Accuracy: 0.7090909\n",
      "epoch: 493 - cost: 0.6404776 -MSE: 7.805488245446482 -Train Accuracy: 0.7030303\n",
      "epoch: 494 - cost: 0.5864374 -MSE: 7.637071255821305 -Train Accuracy: 0.7090909\n",
      "epoch: 495 - cost: 0.6367644 -MSE: 7.798477244669889 -Train Accuracy: 0.7030303\n",
      "epoch: 496 - cost: 0.58356565 -MSE: 7.632602783366709 -Train Accuracy: 0.7090909\n",
      "epoch: 497 - cost: 0.63306046 -MSE: 7.791468852051845 -Train Accuracy: 0.7030303\n",
      "epoch: 498 - cost: 0.5806989 -MSE: 7.6281167372142855 -Train Accuracy: 0.7090909\n",
      "epoch: 499 - cost: 0.6293659 -MSE: 7.784461259712799 -Train Accuracy: 0.7030303\n",
      "epoch: 500 - cost: 0.577837 -MSE: 7.623609491920503 -Train Accuracy: 0.7090909\n",
      "epoch: 501 - cost: 0.625681 -MSE: 7.777456616842145 -Train Accuracy: 0.7030303\n",
      "epoch: 502 - cost: 0.57498014 -MSE: 7.61908349675699 -Train Accuracy: 0.7090909\n",
      "epoch: 503 - cost: 0.6220062 -MSE: 7.770454163899739 -Train Accuracy: 0.7090909\n",
      "epoch: 504 - cost: 0.5721286 -MSE: 7.614541232530467 -Train Accuracy: 0.7090909\n",
      "epoch: 505 - cost: 0.6183417 -MSE: 7.763455955061741 -Train Accuracy: 0.7151515\n",
      "epoch: 506 - cost: 0.5692824 -MSE: 7.6099820226427495 -Train Accuracy: 0.7151515\n",
      "epoch: 507 - cost: 0.61468786 -MSE: 7.756464534746967 -Train Accuracy: 0.7151515\n",
      "epoch: 508 - cost: 0.56644195 -MSE: 7.605405752084938 -Train Accuracy: 0.7090909\n",
      "epoch: 509 - cost: 0.61104476 -MSE: 7.749476384819326 -Train Accuracy: 0.7151515\n",
      "epoch: 510 - cost: 0.563607 -MSE: 7.6008165283312605 -Train Accuracy: 0.7090909\n",
      "epoch: 511 - cost: 0.60741305 -MSE: 7.742495811940736 -Train Accuracy: 0.7151515\n",
      "epoch: 512 - cost: 0.56077826 -MSE: 7.596211061767896 -Train Accuracy: 0.7090909\n",
      "epoch: 513 - cost: 0.6037931 -MSE: 7.735523124886247 -Train Accuracy: 0.72121215\n",
      "epoch: 514 - cost: 0.5579557 -MSE: 7.5915935934817105 -Train Accuracy: 0.7090909\n",
      "epoch: 515 - cost: 0.6001848 -MSE: 7.728559019338661 -Train Accuracy: 0.72121215\n",
      "epoch: 516 - cost: 0.5551393 -MSE: 7.586962175435177 -Train Accuracy: 0.7090909\n",
      "epoch: 517 - cost: 0.59658897 -MSE: 7.721604515062289 -Train Accuracy: 0.72121215\n",
      "epoch: 518 - cost: 0.5523298 -MSE: 7.582319854870566 -Train Accuracy: 0.7090909\n",
      "epoch: 519 - cost: 0.59300613 -MSE: 7.71466364873988 -Train Accuracy: 0.72121215\n",
      "epoch: 520 - cost: 0.5495271 -MSE: 7.577666825524104 -Train Accuracy: 0.7090909\n",
      "epoch: 521 - cost: 0.5894362 -MSE: 7.70773456634244 -Train Accuracy: 0.72121215\n",
      "epoch: 522 - cost: 0.54673135 -MSE: 7.5730033945506126 -Train Accuracy: 0.7090909\n",
      "epoch: 523 - cost: 0.5858796 -MSE: 7.700816113354744 -Train Accuracy: 0.72727275\n",
      "epoch: 524 - cost: 0.5439429 -MSE: 7.568331691247186 -Train Accuracy: 0.7090909\n",
      "epoch: 525 - cost: 0.5823369 -MSE: 7.693915647287906 -Train Accuracy: 0.72727275\n",
      "epoch: 526 - cost: 0.5411622 -MSE: 7.563652591450976 -Train Accuracy: 0.7090909\n",
      "epoch: 527 - cost: 0.57880825 -MSE: 7.687030836332964 -Train Accuracy: 0.72727275\n",
      "epoch: 528 - cost: 0.5383894 -MSE: 7.558968167063646 -Train Accuracy: 0.7090909\n",
      "epoch: 529 - cost: 0.57529473 -MSE: 7.680165229118348 -Train Accuracy: 0.73333335\n",
      "epoch: 530 - cost: 0.5356246 -MSE: 7.554277392571842 -Train Accuracy: 0.7090909\n",
      "epoch: 531 - cost: 0.57179636 -MSE: 7.673318650688453 -Train Accuracy: 0.73333335\n",
      "epoch: 532 - cost: 0.5328684 -MSE: 7.549583874805475 -Train Accuracy: 0.7090909\n",
      "epoch: 533 - cost: 0.56831366 -MSE: 7.666493431876662 -Train Accuracy: 0.73333335\n",
      "epoch: 534 - cost: 0.530121 -MSE: 7.544887668595952 -Train Accuracy: 0.7090909\n",
      "epoch: 535 - cost: 0.5648469 -MSE: 7.659691414423631 -Train Accuracy: 0.73333335\n",
      "epoch: 536 - cost: 0.5273827 -MSE: 7.540190939131448 -Train Accuracy: 0.7090909\n",
      "epoch: 537 - cost: 0.5613967 -MSE: 7.652914516483959 -Train Accuracy: 0.73939395\n",
      "epoch: 538 - cost: 0.5246538 -MSE: 7.5354931739440785 -Train Accuracy: 0.7090909\n",
      "epoch: 539 - cost: 0.5579637 -MSE: 7.646164904191243 -Train Accuracy: 0.74545455\n",
      "epoch: 540 - cost: 0.5219346 -MSE: 7.530797513443883 -Train Accuracy: 0.7090909\n",
      "epoch: 541 - cost: 0.5545481 -MSE: 7.639443389566388 -Train Accuracy: 0.74545455\n",
      "epoch: 542 - cost: 0.51922566 -MSE: 7.526107224004109 -Train Accuracy: 0.7090909\n",
      "epoch: 543 - cost: 0.55115056 -MSE: 7.632754072329827 -Train Accuracy: 0.74545455\n",
      "epoch: 544 - cost: 0.5165272 -MSE: 7.521420818315573 -Train Accuracy: 0.7090909\n",
      "epoch: 545 - cost: 0.54777163 -MSE: 7.62609593658079 -Train Accuracy: 0.74545455\n",
      "epoch: 546 - cost: 0.5138393 -MSE: 7.516740823167977 -Train Accuracy: 0.7151515\n",
      "epoch: 547 - cost: 0.54441166 -MSE: 7.619472938200829 -Train Accuracy: 0.74545455\n",
      "epoch: 548 - cost: 0.51116306 -MSE: 7.512069061975854 -Train Accuracy: 0.72121215\n",
      "epoch: 549 - cost: 0.5410713 -MSE: 7.6128871745850075 -Train Accuracy: 0.74545455\n",
      "epoch: 550 - cost: 0.5084981 -MSE: 7.507406907238755 -Train Accuracy: 0.72727275\n",
      "epoch: 551 - cost: 0.5377511 -MSE: 7.606340368348801 -Train Accuracy: 0.75151515\n",
      "epoch: 552 - cost: 0.5058454 -MSE: 7.5027586935482535 -Train Accuracy: 0.72727275\n",
      "epoch: 553 - cost: 0.5344515 -MSE: 7.599834399220495 -Train Accuracy: 0.75151515\n",
      "epoch: 554 - cost: 0.5032049 -MSE: 7.4981220598847464 -Train Accuracy: 0.72727275\n",
      "epoch: 555 - cost: 0.531173 -MSE: 7.593371447607351 -Train Accuracy: 0.75151515\n",
      "epoch: 556 - cost: 0.5005774 -MSE: 7.493501503298127 -Train Accuracy: 0.72727275\n",
      "epoch: 557 - cost: 0.52791625 -MSE: 7.586954408498891 -Train Accuracy: 0.75151515\n",
      "epoch: 558 - cost: 0.497963 -MSE: 7.488896611006407 -Train Accuracy: 0.73333335\n",
      "epoch: 559 - cost: 0.5246818 -MSE: 7.58058323441311 -Train Accuracy: 0.75151515\n",
      "epoch: 560 - cost: 0.49536234 -MSE: 7.484310944392705 -Train Accuracy: 0.73333335\n",
      "epoch: 561 - cost: 0.52147007 -MSE: 7.574264411380945 -Train Accuracy: 0.75151515\n",
      "epoch: 562 - cost: 0.49277607 -MSE: 7.479748203267594 -Train Accuracy: 0.73939395\n",
      "epoch: 563 - cost: 0.5182821 -MSE: 7.567997091019614 -Train Accuracy: 0.75757575\n",
      "epoch: 564 - cost: 0.49020436 -MSE: 7.475207314376102 -Train Accuracy: 0.74545455\n",
      "epoch: 565 - cost: 0.5151179 -MSE: 7.561784738622386 -Train Accuracy: 0.75757575\n",
      "epoch: 566 - cost: 0.48764753 -MSE: 7.470690805639755 -Train Accuracy: 0.74545455\n",
      "epoch: 567 - cost: 0.511978 -MSE: 7.55562727342225 -Train Accuracy: 0.75757575\n",
      "epoch: 568 - cost: 0.48510617 -MSE: 7.466201570047605 -Train Accuracy: 0.75151515\n",
      "epoch: 569 - cost: 0.5088631 -MSE: 7.549530898879662 -Train Accuracy: 0.75757575\n",
      "epoch: 570 - cost: 0.4825807 -MSE: 7.461741082820438 -Train Accuracy: 0.75151515\n",
      "epoch: 571 - cost: 0.5057739 -MSE: 7.543496712539503 -Train Accuracy: 0.75757575\n",
      "epoch: 572 - cost: 0.48007187 -MSE: 7.45731467467224 -Train Accuracy: 0.75151515\n",
      "epoch: 573 - cost: 0.5027108 -MSE: 7.53752638741765 -Train Accuracy: 0.75757575\n",
      "epoch: 574 - cost: 0.47757995 -MSE: 7.452920570958283 -Train Accuracy: 0.75151515\n",
      "epoch: 575 - cost: 0.49967462 -MSE: 7.531625082054039 -Train Accuracy: 0.75757575\n",
      "epoch: 576 - cost: 0.4751052 -MSE: 7.448562655965919 -Train Accuracy: 0.75151515\n",
      "epoch: 577 - cost: 0.4966657 -MSE: 7.525790756179028 -Train Accuracy: 0.75757575\n",
      "epoch: 578 - cost: 0.47264856 -MSE: 7.44424237716251 -Train Accuracy: 0.75151515\n",
      "epoch: 579 - cost: 0.49368438 -MSE: 7.520031312911915 -Train Accuracy: 0.75757575\n",
      "epoch: 580 - cost: 0.47021016 -MSE: 7.4399628853559046 -Train Accuracy: 0.75151515\n",
      "epoch: 581 - cost: 0.49073148 -MSE: 7.514342181003369 -Train Accuracy: 0.75757575\n",
      "epoch: 582 - cost: 0.46779054 -MSE: 7.435724139717316 -Train Accuracy: 0.75757575\n",
      "epoch: 583 - cost: 0.4878074 -MSE: 7.50873151938872 -Train Accuracy: 0.75757575\n",
      "epoch: 584 - cost: 0.4653903 -MSE: 7.431531890386501 -Train Accuracy: 0.76363635\n",
      "epoch: 585 - cost: 0.48491266 -MSE: 7.503197488231435 -Train Accuracy: 0.75757575\n",
      "epoch: 586 - cost: 0.4630097 -MSE: 7.427385827188628 -Train Accuracy: 0.76363635\n",
      "epoch: 587 - cost: 0.48204762 -MSE: 7.497745982764589 -Train Accuracy: 0.75757575\n",
      "epoch: 588 - cost: 0.46064943 -MSE: 7.42328831612742 -Train Accuracy: 0.76363635\n",
      "epoch: 589 - cost: 0.47921315 -MSE: 7.492377859464194 -Train Accuracy: 0.75757575\n",
      "epoch: 590 - cost: 0.45830983 -MSE: 7.4192439428133286 -Train Accuracy: 0.76363635\n",
      "epoch: 591 - cost: 0.4764095 -MSE: 7.48709664099688 -Train Accuracy: 0.75757575\n",
      "epoch: 592 - cost: 0.45599163 -MSE: 7.41525385703614 -Train Accuracy: 0.76969695\n",
      "epoch: 593 - cost: 0.4736371 -MSE: 7.481903429988051 -Train Accuracy: 0.76363635\n",
      "epoch: 594 - cost: 0.4536946 -MSE: 7.411318364673856 -Train Accuracy: 0.76969695\n",
      "epoch: 595 - cost: 0.47089654 -MSE: 7.476801359125629 -Train Accuracy: 0.76363635\n",
      "epoch: 596 - cost: 0.45141998 -MSE: 7.407442349328186 -Train Accuracy: 0.76363635\n",
      "epoch: 597 - cost: 0.46818805 -MSE: 7.471790401223648 -Train Accuracy: 0.76363635\n",
      "epoch: 598 - cost: 0.44916785 -MSE: 7.4036269024922845 -Train Accuracy: 0.76363635\n",
      "epoch: 599 - cost: 0.4655123 -MSE: 7.466875576694259 -Train Accuracy: 0.76969695\n",
      "epoch: 600 - cost: 0.44693863 -MSE: 7.399874099930703 -Train Accuracy: 0.76363635\n",
      "epoch: 601 - cost: 0.46286935 -MSE: 7.462057742170119 -Train Accuracy: 0.76969695\n",
      "epoch: 602 - cost: 0.44473267 -MSE: 7.396186772485805 -Train Accuracy: 0.76969695\n",
      "epoch: 603 - cost: 0.46025988 -MSE: 7.457338732482521 -Train Accuracy: 0.76969695\n",
      "epoch: 604 - cost: 0.44255057 -MSE: 7.392567364509863 -Train Accuracy: 0.77575755\n",
      "epoch: 605 - cost: 0.45768383 -MSE: 7.452719440348913 -Train Accuracy: 0.76969695\n",
      "epoch: 606 - cost: 0.4403924 -MSE: 7.38901658357701 -Train Accuracy: 0.7818182\n",
      "epoch: 607 - cost: 0.45514202 -MSE: 7.448204486954277 -Train Accuracy: 0.76969695\n",
      "epoch: 608 - cost: 0.43825892 -MSE: 7.385536240931683 -Train Accuracy: 0.7818182\n",
      "epoch: 609 - cost: 0.4526345 -MSE: 7.4437928844759895 -Train Accuracy: 0.76969695\n",
      "epoch: 610 - cost: 0.43615007 -MSE: 7.382129456851852 -Train Accuracy: 0.7818182\n",
      "epoch: 611 - cost: 0.45016146 -MSE: 7.439487885103706 -Train Accuracy: 0.76969695\n",
      "epoch: 612 - cost: 0.4340666 -MSE: 7.378799975051107 -Train Accuracy: 0.7818182\n",
      "epoch: 613 - cost: 0.4477232 -MSE: 7.435290675274488 -Train Accuracy: 0.76969695\n",
      "epoch: 614 - cost: 0.43200836 -MSE: 7.375544776815356 -Train Accuracy: 0.7818182\n",
      "epoch: 615 - cost: 0.4453198 -MSE: 7.431201441762482 -Train Accuracy: 0.76969695\n",
      "epoch: 616 - cost: 0.42997584 -MSE: 7.37236931221538 -Train Accuracy: 0.7818182\n",
      "epoch: 617 - cost: 0.44295147 -MSE: 7.427223182044757 -Train Accuracy: 0.76969695\n",
      "epoch: 618 - cost: 0.42796928 -MSE: 7.369273518726621 -Train Accuracy: 0.7878788\n",
      "epoch: 619 - cost: 0.44061843 -MSE: 7.423356502651139 -Train Accuracy: 0.76969695\n",
      "epoch: 620 - cost: 0.42598882 -MSE: 7.366260926823212 -Train Accuracy: 0.7878788\n",
      "epoch: 621 - cost: 0.43832073 -MSE: 7.419600719005018 -Train Accuracy: 0.76969695\n",
      "epoch: 622 - cost: 0.4240349 -MSE: 7.363329634274844 -Train Accuracy: 0.7878788\n",
      "epoch: 623 - cost: 0.43605846 -MSE: 7.4159597002750655 -Train Accuracy: 0.77575755\n",
      "epoch: 624 - cost: 0.42210734 -MSE: 7.36048472584569 -Train Accuracy: 0.7878788\n",
      "epoch: 625 - cost: 0.43383166 -MSE: 7.412433492320918 -Train Accuracy: 0.77575755\n",
      "epoch: 626 - cost: 0.42020658 -MSE: 7.357725768722836 -Train Accuracy: 0.7878788\n",
      "epoch: 627 - cost: 0.43164015 -MSE: 7.4090209453204 -Train Accuracy: 0.77575755\n",
      "epoch: 628 - cost: 0.41833255 -MSE: 7.35505429885278 -Train Accuracy: 0.7939394\n",
      "epoch: 629 - cost: 0.42948413 -MSE: 7.405725524524588 -Train Accuracy: 0.77575755\n",
      "epoch: 630 - cost: 0.4164857 -MSE: 7.3524720385954 -Train Accuracy: 0.8\n",
      "epoch: 631 - cost: 0.42736372 -MSE: 7.402548627831271 -Train Accuracy: 0.77575755\n",
      "epoch: 632 - cost: 0.4146658 -MSE: 7.349979096065727 -Train Accuracy: 0.8\n",
      "epoch: 633 - cost: 0.42527837 -MSE: 7.399485211356819 -Train Accuracy: 0.77575755\n",
      "epoch: 634 - cost: 0.4128728 -MSE: 7.34757522555732 -Train Accuracy: 0.8\n",
      "epoch: 635 - cost: 0.42322803 -MSE: 7.3965401409503455 -Train Accuracy: 0.77575755\n",
      "epoch: 636 - cost: 0.41110668 -MSE: 7.345263122809714 -Train Accuracy: 0.8\n",
      "epoch: 637 - cost: 0.42121258 -MSE: 7.393710277004637 -Train Accuracy: 0.77575755\n",
      "epoch: 638 - cost: 0.4093676 -MSE: 7.343042970746976 -Train Accuracy: 0.8\n",
      "epoch: 639 - cost: 0.4192318 -MSE: 7.390997364642179 -Train Accuracy: 0.77575755\n",
      "epoch: 640 - cost: 0.40765542 -MSE: 7.3409137780026 -Train Accuracy: 0.8\n",
      "epoch: 641 - cost: 0.41728538 -MSE: 7.388399607757319 -Train Accuracy: 0.77575755\n",
      "epoch: 642 - cost: 0.40596992 -MSE: 7.338875663208917 -Train Accuracy: 0.8\n",
      "epoch: 643 - cost: 0.4153731 -MSE: 7.385917699510016 -Train Accuracy: 0.7818182\n",
      "epoch: 644 - cost: 0.40431103 -MSE: 7.336931203276157 -Train Accuracy: 0.8060606\n",
      "epoch: 645 - cost: 0.41349438 -MSE: 7.383550724173041 -Train Accuracy: 0.7818182\n",
      "epoch: 646 - cost: 0.40267837 -MSE: 7.335077825659022 -Train Accuracy: 0.8121212\n",
      "epoch: 647 - cost: 0.41164908 -MSE: 7.38129713346285 -Train Accuracy: 0.7818182\n",
      "epoch: 648 - cost: 0.40107208 -MSE: 7.333316761626634 -Train Accuracy: 0.8181818\n",
      "epoch: 649 - cost: 0.4098365 -MSE: 7.37915840654545 -Train Accuracy: 0.7818182\n",
      "epoch: 650 - cost: 0.39949155 -MSE: 7.3316483807704955 -Train Accuracy: 0.8181818\n",
      "epoch: 651 - cost: 0.40805656 -MSE: 7.377132073823478 -Train Accuracy: 0.7818182\n",
      "epoch: 652 - cost: 0.39793682 -MSE: 7.330070818359725 -Train Accuracy: 0.8181818\n",
      "epoch: 653 - cost: 0.4063087 -MSE: 7.375216008883489 -Train Accuracy: 0.7818182\n",
      "epoch: 654 - cost: 0.39640743 -MSE: 7.328585884937011 -Train Accuracy: 0.8181818\n",
      "epoch: 655 - cost: 0.40459216 -MSE: 7.373409584283269 -Train Accuracy: 0.7818182\n",
      "epoch: 656 - cost: 0.39490297 -MSE: 7.327188397870517 -Train Accuracy: 0.8181818\n",
      "epoch: 657 - cost: 0.40290657 -MSE: 7.371710583149541 -Train Accuracy: 0.7818182\n",
      "epoch: 658 - cost: 0.39342323 -MSE: 7.3258831510694575 -Train Accuracy: 0.8181818\n",
      "epoch: 659 - cost: 0.4012514 -MSE: 7.370118752457829 -Train Accuracy: 0.7818182\n",
      "epoch: 660 - cost: 0.3919677 -MSE: 7.3246650594629745 -Train Accuracy: 0.8181818\n",
      "epoch: 661 - cost: 0.39962617 -MSE: 7.36863261702464 -Train Accuracy: 0.7818182\n",
      "epoch: 662 - cost: 0.39053622 -MSE: 7.323536666916054 -Train Accuracy: 0.8181818\n",
      "epoch: 663 - cost: 0.3980301 -MSE: 7.367250712353589 -Train Accuracy: 0.7818182\n",
      "epoch: 664 - cost: 0.38912806 -MSE: 7.322493819874102 -Train Accuracy: 0.8181818\n",
      "epoch: 665 - cost: 0.3964626 -MSE: 7.365969348531012 -Train Accuracy: 0.7878788\n",
      "epoch: 666 - cost: 0.3877428 -MSE: 7.321537272165626 -Train Accuracy: 0.8242424\n",
      "epoch: 667 - cost: 0.39492297 -MSE: 7.364788606876466 -Train Accuracy: 0.7878788\n",
      "epoch: 668 - cost: 0.38638002 -MSE: 7.320664715065153 -Train Accuracy: 0.8242424\n",
      "epoch: 669 - cost: 0.39341047 -MSE: 7.363703789540784 -Train Accuracy: 0.7878788\n",
      "epoch: 670 - cost: 0.3850392 -MSE: 7.3198759271069616 -Train Accuracy: 0.8242424\n",
      "epoch: 671 - cost: 0.3919245 -MSE: 7.3627148922507635 -Train Accuracy: 0.7878788\n",
      "epoch: 672 - cost: 0.38371968 -MSE: 7.319166096683156 -Train Accuracy: 0.8242424\n",
      "epoch: 673 - cost: 0.39046413 -MSE: 7.3618175370794 -Train Accuracy: 0.7878788\n",
      "epoch: 674 - cost: 0.382421 -MSE: 7.318537419747778 -Train Accuracy: 0.8242424\n",
      "epoch: 675 - cost: 0.38902903 -MSE: 7.36101277619904 -Train Accuracy: 0.7878788\n",
      "epoch: 676 - cost: 0.38114265 -MSE: 7.31798509560179 -Train Accuracy: 0.830303\n",
      "epoch: 677 - cost: 0.38761815 -MSE: 7.360293888713817 -Train Accuracy: 0.7878788\n",
      "epoch: 678 - cost: 0.37988418 -MSE: 7.317510561670959 -Train Accuracy: 0.830303\n",
      "epoch: 679 - cost: 0.38623083 -MSE: 7.3596615219395645 -Train Accuracy: 0.7878788\n",
      "epoch: 680 - cost: 0.37864476 -MSE: 7.317110608287394 -Train Accuracy: 0.8363636\n",
      "epoch: 681 - cost: 0.38486648 -MSE: 7.359112762577546 -Train Accuracy: 0.7878788\n",
      "epoch: 682 - cost: 0.3774241 -MSE: 7.316783622237809 -Train Accuracy: 0.8363636\n",
      "epoch: 683 - cost: 0.38352445 -MSE: 7.358646390976877 -Train Accuracy: 0.7939394\n",
      "epoch: 684 - cost: 0.37622148 -MSE: 7.316527569014852 -Train Accuracy: 0.8363636\n",
      "epoch: 685 - cost: 0.38220364 -MSE: 7.3582566628257275 -Train Accuracy: 0.7939394\n",
      "epoch: 686 - cost: 0.3750363 -MSE: 7.3163405614633135 -Train Accuracy: 0.8363636\n",
      "epoch: 687 - cost: 0.3809036 -MSE: 7.3579447216279865 -Train Accuracy: 0.7939394\n",
      "epoch: 688 - cost: 0.37386802 -MSE: 7.316220418933459 -Train Accuracy: 0.8363636\n",
      "epoch: 689 - cost: 0.37962347 -MSE: 7.357704770262607 -Train Accuracy: 0.7939394\n",
      "epoch: 690 - cost: 0.37271598 -MSE: 7.316165895859403 -Train Accuracy: 0.8363636\n",
      "epoch: 691 - cost: 0.3783627 -MSE: 7.357535364029383 -Train Accuracy: 0.7939394\n",
      "epoch: 692 - cost: 0.37157983 -MSE: 7.316174395450743 -Train Accuracy: 0.8363636\n",
      "epoch: 693 - cost: 0.3771205 -MSE: 7.357436760071411 -Train Accuracy: 0.7939394\n",
      "epoch: 694 - cost: 0.3704588 -MSE: 7.316242919923822 -Train Accuracy: 0.8363636\n",
      "epoch: 695 - cost: 0.37589613 -MSE: 7.3574002933520815 -Train Accuracy: 0.8\n",
      "epoch: 696 - cost: 0.36935237 -MSE: 7.31637223394552 -Train Accuracy: 0.8363636\n",
      "epoch: 697 - cost: 0.37468874 -MSE: 7.357430251768124 -Train Accuracy: 0.8\n",
      "epoch: 698 - cost: 0.36825997 -MSE: 7.316559454185313 -Train Accuracy: 0.8363636\n",
      "epoch: 699 - cost: 0.37349793 -MSE: 7.357521258829303 -Train Accuracy: 0.8060606\n",
      "epoch: 700 - cost: 0.36718088 -MSE: 7.316801339915098 -Train Accuracy: 0.8363636\n",
      "epoch: 701 - cost: 0.3723229 -MSE: 7.357671070732625 -Train Accuracy: 0.8060606\n",
      "epoch: 702 - cost: 0.36611483 -MSE: 7.317097480877508 -Train Accuracy: 0.8363636\n",
      "epoch: 703 - cost: 0.37116295 -MSE: 7.357877664632142 -Train Accuracy: 0.8060606\n",
      "epoch: 704 - cost: 0.36506116 -MSE: 7.317444559542945 -Train Accuracy: 0.8363636\n",
      "epoch: 705 - cost: 0.37001753 -MSE: 7.358137420449347 -Train Accuracy: 0.8060606\n",
      "epoch: 706 - cost: 0.36401954 -MSE: 7.317841506980807 -Train Accuracy: 0.8424242\n",
      "epoch: 707 - cost: 0.36888617 -MSE: 7.358448707896852 -Train Accuracy: 0.8121212\n",
      "epoch: 708 - cost: 0.36298928 -MSE: 7.318287800157818 -Train Accuracy: 0.8424242\n",
      "epoch: 709 - cost: 0.36776793 -MSE: 7.358811863904626 -Train Accuracy: 0.8242424\n",
      "epoch: 710 - cost: 0.36196986 -MSE: 7.318780243446923 -Train Accuracy: 0.8424242\n",
      "epoch: 711 - cost: 0.3666627 -MSE: 7.359222171636935 -Train Accuracy: 0.8242424\n",
      "epoch: 712 - cost: 0.36096105 -MSE: 7.319318087068371 -Train Accuracy: 0.8424242\n",
      "epoch: 713 - cost: 0.36556974 -MSE: 7.359679672447271 -Train Accuracy: 0.8242424\n",
      "epoch: 714 - cost: 0.35996228 -MSE: 7.3198984545981185 -Train Accuracy: 0.8424242\n",
      "epoch: 715 - cost: 0.3644885 -MSE: 7.360178364978954 -Train Accuracy: 0.8242424\n",
      "epoch: 716 - cost: 0.35897318 -MSE: 7.320521150324233 -Train Accuracy: 0.8484849\n",
      "epoch: 717 - cost: 0.36341864 -MSE: 7.360723179677923 -Train Accuracy: 0.830303\n",
      "epoch: 718 - cost: 0.35799327 -MSE: 7.321184164394421 -Train Accuracy: 0.8484849\n",
      "epoch: 719 - cost: 0.3623594 -MSE: 7.3613077070873025 -Train Accuracy: 0.830303\n",
      "epoch: 720 - cost: 0.35702214 -MSE: 7.321886061694538 -Train Accuracy: 0.8484849\n",
      "epoch: 721 - cost: 0.36131036 -MSE: 7.361928426132313 -Train Accuracy: 0.830303\n",
      "epoch: 722 - cost: 0.3560595 -MSE: 7.322621692380951 -Train Accuracy: 0.8484849\n",
      "epoch: 723 - cost: 0.36027133 -MSE: 7.3625891323704495 -Train Accuracy: 0.830303\n",
      "epoch: 724 - cost: 0.35510474 -MSE: 7.323395690111335 -Train Accuracy: 0.8484849\n",
      "epoch: 725 - cost: 0.35924163 -MSE: 7.363284928633238 -Train Accuracy: 0.830303\n",
      "epoch: 726 - cost: 0.3541579 -MSE: 7.3242056620623925 -Train Accuracy: 0.8484849\n",
      "epoch: 727 - cost: 0.3582211 -MSE: 7.364014048040598 -Train Accuracy: 0.830303\n",
      "epoch: 728 - cost: 0.3532186 -MSE: 7.325047720785694 -Train Accuracy: 0.8484849\n",
      "epoch: 729 - cost: 0.35720956 -MSE: 7.364777186347538 -Train Accuracy: 0.830303\n",
      "epoch: 730 - cost: 0.35228652 -MSE: 7.325922071195984 -Train Accuracy: 0.8484849\n",
      "epoch: 731 - cost: 0.35620645 -MSE: 7.36557278840128 -Train Accuracy: 0.830303\n",
      "epoch: 732 - cost: 0.3513614 -MSE: 7.326828808057265 -Train Accuracy: 0.8484849\n",
      "epoch: 733 - cost: 0.35521144 -MSE: 7.366397824829734 -Train Accuracy: 0.830303\n",
      "epoch: 734 - cost: 0.3504429 -MSE: 7.327763414949451 -Train Accuracy: 0.8484849\n",
      "epoch: 735 - cost: 0.35422418 -MSE: 7.367254436866678 -Train Accuracy: 0.8363636\n",
      "epoch: 736 - cost: 0.34953085 -MSE: 7.3287312820018675 -Train Accuracy: 0.8484849\n",
      "epoch: 737 - cost: 0.35324472 -MSE: 7.368138096704066 -Train Accuracy: 0.8363636\n",
      "epoch: 738 - cost: 0.3486251 -MSE: 7.329724410692068 -Train Accuracy: 0.8484849\n",
      "epoch: 739 - cost: 0.35227257 -MSE: 7.36904999460001 -Train Accuracy: 0.8363636\n",
      "epoch: 740 - cost: 0.3477252 -MSE: 7.3307461811577 -Train Accuracy: 0.8545455\n",
      "epoch: 741 - cost: 0.35130736 -MSE: 7.3699875598325075 -Train Accuracy: 0.8363636\n",
      "epoch: 742 - cost: 0.34683138 -MSE: 7.331795287747427 -Train Accuracy: 0.8545455\n",
      "epoch: 743 - cost: 0.35034925 -MSE: 7.3709516784054285 -Train Accuracy: 0.8363636\n",
      "epoch: 744 - cost: 0.34594312 -MSE: 7.332870829260062 -Train Accuracy: 0.8545455\n",
      "epoch: 745 - cost: 0.34939766 -MSE: 7.371941879799501 -Train Accuracy: 0.8363636\n",
      "epoch: 746 - cost: 0.3450601 -MSE: 7.333968948479954 -Train Accuracy: 0.8545455\n",
      "epoch: 747 - cost: 0.3484526 -MSE: 7.372956563433046 -Train Accuracy: 0.8363636\n",
      "epoch: 748 - cost: 0.34418267 -MSE: 7.335094887115053 -Train Accuracy: 0.8545455\n",
      "epoch: 749 - cost: 0.3475139 -MSE: 7.373995207743579 -Train Accuracy: 0.8363636\n",
      "epoch: 750 - cost: 0.3433104 -MSE: 7.336244928203717 -Train Accuracy: 0.8545455\n",
      "epoch: 751 - cost: 0.34658137 -MSE: 7.375057695840873 -Train Accuracy: 0.8363636\n",
      "epoch: 752 - cost: 0.3424432 -MSE: 7.337418029153665 -Train Accuracy: 0.8545455\n",
      "epoch: 753 - cost: 0.34565493 -MSE: 7.376142220952734 -Train Accuracy: 0.8424242\n",
      "epoch: 754 - cost: 0.34158105 -MSE: 7.338615538007719 -Train Accuracy: 0.8545455\n",
      "epoch: 755 - cost: 0.34473428 -MSE: 7.377250792607916 -Train Accuracy: 0.8424242\n",
      "epoch: 756 - cost: 0.34072366 -MSE: 7.339835167733922 -Train Accuracy: 0.8545455\n",
      "epoch: 757 - cost: 0.34381944 -MSE: 7.3783813977347465 -Train Accuracy: 0.8424242\n",
      "epoch: 758 - cost: 0.339871 -MSE: 7.341079130175409 -Train Accuracy: 0.8545455\n",
      "epoch: 759 - cost: 0.3429103 -MSE: 7.37953274351069 -Train Accuracy: 0.8424242\n",
      "epoch: 760 - cost: 0.33902293 -MSE: 7.342344070000628 -Train Accuracy: 0.8545455\n",
      "epoch: 761 - cost: 0.34200642 -MSE: 7.3807050007917345 -Train Accuracy: 0.8424242\n",
      "epoch: 762 - cost: 0.3381796 -MSE: 7.343629021714174 -Train Accuracy: 0.8545455\n",
      "epoch: 763 - cost: 0.3411082 -MSE: 7.381899624861664 -Train Accuracy: 0.8424242\n",
      "epoch: 764 - cost: 0.33734062 -MSE: 7.344938583195918 -Train Accuracy: 0.8545455\n",
      "epoch: 765 - cost: 0.3402152 -MSE: 7.383114411884579 -Train Accuracy: 0.8424242\n",
      "epoch: 766 - cost: 0.3365059 -MSE: 7.346267419702231 -Train Accuracy: 0.8545455\n",
      "epoch: 767 - cost: 0.33932737 -MSE: 7.3843498879842615 -Train Accuracy: 0.8484849\n",
      "epoch: 768 - cost: 0.3356757 -MSE: 7.347619002128229 -Train Accuracy: 0.8545455\n",
      "epoch: 769 - cost: 0.33844474 -MSE: 7.385606638152118 -Train Accuracy: 0.8484849\n",
      "epoch: 770 - cost: 0.3348496 -MSE: 7.348990415844309 -Train Accuracy: 0.8606061\n",
      "epoch: 771 - cost: 0.33756694 -MSE: 7.386882819663792 -Train Accuracy: 0.8484849\n",
      "epoch: 772 - cost: 0.33402756 -MSE: 7.3503828110818965 -Train Accuracy: 0.8606061\n",
      "epoch: 773 - cost: 0.33669415 -MSE: 7.388179229351656 -Train Accuracy: 0.8484849\n",
      "epoch: 774 - cost: 0.33320963 -MSE: 7.351794373134824 -Train Accuracy: 0.8606061\n",
      "epoch: 775 - cost: 0.33582625 -MSE: 7.389493387014805 -Train Accuracy: 0.8484849\n",
      "epoch: 776 - cost: 0.33239585 -MSE: 7.35322813914175 -Train Accuracy: 0.8606061\n",
      "epoch: 777 - cost: 0.33496305 -MSE: 7.39082849447151 -Train Accuracy: 0.8484849\n",
      "epoch: 778 - cost: 0.3315858 -MSE: 7.354681499461706 -Train Accuracy: 0.8606061\n",
      "epoch: 779 - cost: 0.33410448 -MSE: 7.392182765707643 -Train Accuracy: 0.8484849\n",
      "epoch: 780 - cost: 0.3307798 -MSE: 7.35615304920873 -Train Accuracy: 0.8606061\n",
      "epoch: 781 - cost: 0.3332506 -MSE: 7.393556996244862 -Train Accuracy: 0.8484849\n",
      "epoch: 782 - cost: 0.32997745 -MSE: 7.357644548478721 -Train Accuracy: 0.8606061\n",
      "epoch: 783 - cost: 0.3324011 -MSE: 7.394949908269065 -Train Accuracy: 0.8484849\n",
      "epoch: 784 - cost: 0.32917884 -MSE: 7.359156119518719 -Train Accuracy: 0.8606061\n",
      "epoch: 785 - cost: 0.33155602 -MSE: 7.396359039333977 -Train Accuracy: 0.8484849\n",
      "epoch: 786 - cost: 0.32838392 -MSE: 7.360683773859299 -Train Accuracy: 0.8606061\n",
      "epoch: 787 - cost: 0.3307152 -MSE: 7.397786891776875 -Train Accuracy: 0.8484849\n",
      "epoch: 788 - cost: 0.32759255 -MSE: 7.362232620136048 -Train Accuracy: 0.8606061\n",
      "epoch: 789 - cost: 0.3298787 -MSE: 7.399233638142786 -Train Accuracy: 0.8484849\n",
      "epoch: 790 - cost: 0.32680452 -MSE: 7.363798538238484 -Train Accuracy: 0.8606061\n",
      "epoch: 791 - cost: 0.32904607 -MSE: 7.400698112296833 -Train Accuracy: 0.8484849\n",
      "epoch: 792 - cost: 0.32601994 -MSE: 7.365385826685191 -Train Accuracy: 0.8606061\n",
      "epoch: 793 - cost: 0.32821757 -MSE: 7.402179638599491 -Train Accuracy: 0.8484849\n",
      "epoch: 794 - cost: 0.32523876 -MSE: 7.366988713145046 -Train Accuracy: 0.8606061\n",
      "epoch: 795 - cost: 0.32739308 -MSE: 7.403678615485497 -Train Accuracy: 0.8484849\n",
      "epoch: 796 - cost: 0.32446074 -MSE: 7.368609280343365 -Train Accuracy: 0.8606061\n",
      "epoch: 797 - cost: 0.32657236 -MSE: 7.405195712252614 -Train Accuracy: 0.8484849\n",
      "epoch: 798 - cost: 0.32368597 -MSE: 7.370247533494305 -Train Accuracy: 0.8666667\n",
      "epoch: 799 - cost: 0.3257555 -MSE: 7.406728698204789 -Train Accuracy: 0.8484849\n",
      "epoch: 800 - cost: 0.32291424 -MSE: 7.371904801823549 -Train Accuracy: 0.8666667\n",
      "epoch: 801 - cost: 0.32494223 -MSE: 7.408279220777891 -Train Accuracy: 0.8484849\n",
      "epoch: 802 - cost: 0.32214555 -MSE: 7.373580096785028 -Train Accuracy: 0.8666667\n",
      "epoch: 803 - cost: 0.3241325 -MSE: 7.409846955593101 -Train Accuracy: 0.8484849\n",
      "epoch: 804 - cost: 0.32137975 -MSE: 7.375272223519183 -Train Accuracy: 0.8666667\n",
      "epoch: 805 - cost: 0.32332623 -MSE: 7.411430050309962 -Train Accuracy: 0.8484849\n",
      "epoch: 806 - cost: 0.32061672 -MSE: 7.376981366655777 -Train Accuracy: 0.8666667\n",
      "epoch: 807 - cost: 0.32252336 -MSE: 7.413030674003072 -Train Accuracy: 0.8484849\n",
      "epoch: 808 - cost: 0.3198566 -MSE: 7.3787068130831255 -Train Accuracy: 0.8727273\n",
      "epoch: 809 - cost: 0.32172373 -MSE: 7.414645078013921 -Train Accuracy: 0.8484849\n",
      "epoch: 810 - cost: 0.31909898 -MSE: 7.3804481494361465 -Train Accuracy: 0.8727273\n",
      "epoch: 811 - cost: 0.32092708 -MSE: 7.416275171208748 -Train Accuracy: 0.8545455\n",
      "epoch: 812 - cost: 0.31834385 -MSE: 7.3822036593764535 -Train Accuracy: 0.8727273\n",
      "epoch: 813 - cost: 0.32013363 -MSE: 7.417919757494913 -Train Accuracy: 0.8545455\n",
      "epoch: 814 - cost: 0.31759134 -MSE: 7.383977040344743 -Train Accuracy: 0.8727273\n",
      "epoch: 815 - cost: 0.3193431 -MSE: 7.419581422840971 -Train Accuracy: 0.8545455\n",
      "epoch: 816 - cost: 0.3168412 -MSE: 7.385768091346968 -Train Accuracy: 0.8727273\n",
      "epoch: 817 - cost: 0.3185554 -MSE: 7.421256579538305 -Train Accuracy: 0.8545455\n",
      "epoch: 818 - cost: 0.31609333 -MSE: 7.387572891427272 -Train Accuracy: 0.8727273\n",
      "epoch: 819 - cost: 0.31777054 -MSE: 7.422945030501066 -Train Accuracy: 0.8606061\n",
      "epoch: 820 - cost: 0.31534767 -MSE: 7.389393650290163 -Train Accuracy: 0.8727273\n",
      "epoch: 821 - cost: 0.31698826 -MSE: 7.424648433700944 -Train Accuracy: 0.8606061\n",
      "epoch: 822 - cost: 0.3146041 -MSE: 7.391229368377096 -Train Accuracy: 0.8727273\n",
      "epoch: 823 - cost: 0.31620854 -MSE: 7.426365973399586 -Train Accuracy: 0.8606061\n",
      "epoch: 824 - cost: 0.3138627 -MSE: 7.393079933835604 -Train Accuracy: 0.8727273\n",
      "epoch: 825 - cost: 0.3154313 -MSE: 7.428097751033577 -Train Accuracy: 0.8606061\n",
      "epoch: 826 - cost: 0.31312317 -MSE: 7.39494438979853 -Train Accuracy: 0.8787879\n",
      "epoch: 827 - cost: 0.31465638 -MSE: 7.429841154059348 -Train Accuracy: 0.8606061\n",
      "epoch: 828 - cost: 0.3123855 -MSE: 7.396823942211532 -Train Accuracy: 0.8787879\n",
      "epoch: 829 - cost: 0.31388387 -MSE: 7.431597491647016 -Train Accuracy: 0.8606061\n",
      "epoch: 830 - cost: 0.3116497 -MSE: 7.398717767111048 -Train Accuracy: 0.8787879\n",
      "epoch: 831 - cost: 0.31311357 -MSE: 7.43336801732264 -Train Accuracy: 0.8606061\n",
      "epoch: 832 - cost: 0.31091574 -MSE: 7.400627083087404 -Train Accuracy: 0.8787879\n",
      "epoch: 833 - cost: 0.3123452 -MSE: 7.4351500221970115 -Train Accuracy: 0.8606061\n",
      "epoch: 834 - cost: 0.3101833 -MSE: 7.402549573566944 -Train Accuracy: 0.8848485\n",
      "epoch: 835 - cost: 0.31157905 -MSE: 7.43694523185289 -Train Accuracy: 0.8606061\n",
      "epoch: 836 - cost: 0.3094524 -MSE: 7.404483620350051 -Train Accuracy: 0.8848485\n",
      "epoch: 837 - cost: 0.31081468 -MSE: 7.43875115739533 -Train Accuracy: 0.8606061\n",
      "epoch: 838 - cost: 0.30872297 -MSE: 7.406432557648474 -Train Accuracy: 0.8848485\n",
      "epoch: 839 - cost: 0.31005204 -MSE: 7.440569447259525 -Train Accuracy: 0.8606061\n",
      "epoch: 840 - cost: 0.30799487 -MSE: 7.408394292764596 -Train Accuracy: 0.8848485\n",
      "epoch: 841 - cost: 0.30929118 -MSE: 7.44239800724559 -Train Accuracy: 0.8606061\n",
      "epoch: 842 - cost: 0.307268 -MSE: 7.410369364876867 -Train Accuracy: 0.8848485\n",
      "epoch: 843 - cost: 0.30853197 -MSE: 7.444236783992063 -Train Accuracy: 0.8606061\n",
      "epoch: 844 - cost: 0.30654252 -MSE: 7.412356061526948 -Train Accuracy: 0.8848485\n",
      "epoch: 845 - cost: 0.30777436 -MSE: 7.4460873308221815 -Train Accuracy: 0.8606061\n",
      "epoch: 846 - cost: 0.3058182 -MSE: 7.4143568121605385 -Train Accuracy: 0.8848485\n",
      "epoch: 847 - cost: 0.30701837 -MSE: 7.447948453187477 -Train Accuracy: 0.8606061\n",
      "epoch: 848 - cost: 0.305095 -MSE: 7.416368798985778 -Train Accuracy: 0.8848485\n",
      "epoch: 849 - cost: 0.3062637 -MSE: 7.449820490580007 -Train Accuracy: 0.8666667\n",
      "epoch: 850 - cost: 0.30437282 -MSE: 7.418393114386417 -Train Accuracy: 0.8848485\n",
      "epoch: 851 - cost: 0.3055104 -MSE: 7.451701027208045 -Train Accuracy: 0.8666667\n",
      "epoch: 852 - cost: 0.30365178 -MSE: 7.420428707543278 -Train Accuracy: 0.8848485\n",
      "epoch: 853 - cost: 0.30475846 -MSE: 7.453591863876936 -Train Accuracy: 0.8666667\n",
      "epoch: 854 - cost: 0.30293155 -MSE: 7.4224782807936105 -Train Accuracy: 0.8848485\n",
      "epoch: 855 - cost: 0.3040077 -MSE: 7.455493268827178 -Train Accuracy: 0.8666667\n",
      "epoch: 856 - cost: 0.30221233 -MSE: 7.42453833892345 -Train Accuracy: 0.8848485\n",
      "epoch: 857 - cost: 0.3032582 -MSE: 7.45740060967493 -Train Accuracy: 0.8666667\n",
      "epoch: 858 - cost: 0.30149373 -MSE: 7.4266078606753 -Train Accuracy: 0.8848485\n",
      "epoch: 859 - cost: 0.30250975 -MSE: 7.459319774413628 -Train Accuracy: 0.8666667\n",
      "epoch: 860 - cost: 0.30077597 -MSE: 7.42869049649534 -Train Accuracy: 0.8848485\n",
      "epoch: 861 - cost: 0.30176228 -MSE: 7.461246021500621 -Train Accuracy: 0.8666667\n",
      "epoch: 862 - cost: 0.3000588 -MSE: 7.430782443889024 -Train Accuracy: 0.8848485\n",
      "epoch: 863 - cost: 0.3010156 -MSE: 7.463181355814881 -Train Accuracy: 0.8666667\n",
      "epoch: 864 - cost: 0.29934224 -MSE: 7.432884972522318 -Train Accuracy: 0.8848485\n",
      "epoch: 865 - cost: 0.30027002 -MSE: 7.465123455296817 -Train Accuracy: 0.8666667\n",
      "epoch: 866 - cost: 0.29862645 -MSE: 7.4350014772582 -Train Accuracy: 0.8848485\n",
      "epoch: 867 - cost: 0.29952526 -MSE: 7.467075856150968 -Train Accuracy: 0.8666667\n",
      "epoch: 868 - cost: 0.29791108 -MSE: 7.437126138097296 -Train Accuracy: 0.8848485\n",
      "epoch: 869 - cost: 0.29878137 -MSE: 7.469036756699067 -Train Accuracy: 0.8666667\n",
      "epoch: 870 - cost: 0.2971962 -MSE: 7.439261871038904 -Train Accuracy: 0.8848485\n",
      "epoch: 871 - cost: 0.2980383 -MSE: 7.471002572544437 -Train Accuracy: 0.8666667\n",
      "epoch: 872 - cost: 0.2964819 -MSE: 7.441404660437019 -Train Accuracy: 0.8848485\n",
      "epoch: 873 - cost: 0.29729572 -MSE: 7.47297618473045 -Train Accuracy: 0.8666667\n",
      "epoch: 874 - cost: 0.2957679 -MSE: 7.443561300350289 -Train Accuracy: 0.8848485\n",
      "epoch: 875 - cost: 0.29655403 -MSE: 7.4749585632827555 -Train Accuracy: 0.8666667\n",
      "epoch: 876 - cost: 0.29505432 -MSE: 7.445725535989755 -Train Accuracy: 0.8848485\n",
      "epoch: 877 - cost: 0.29581285 -MSE: 7.476946595828841 -Train Accuracy: 0.8666667\n",
      "epoch: 878 - cost: 0.29434115 -MSE: 7.44790025472254 -Train Accuracy: 0.8848485\n",
      "epoch: 879 - cost: 0.29507232 -MSE: 7.478943181566486 -Train Accuracy: 0.8666667\n",
      "epoch: 880 - cost: 0.29362822 -MSE: 7.450086065815526 -Train Accuracy: 0.8848485\n",
      "epoch: 881 - cost: 0.2943324 -MSE: 7.480945232110204 -Train Accuracy: 0.8666667\n",
      "epoch: 882 - cost: 0.29291558 -MSE: 7.452279453297075 -Train Accuracy: 0.8848485\n",
      "epoch: 883 - cost: 0.29359296 -MSE: 7.482954932293622 -Train Accuracy: 0.8666667\n",
      "epoch: 884 - cost: 0.2922033 -MSE: 7.454483605858459 -Train Accuracy: 0.8848485\n",
      "epoch: 885 - cost: 0.29285416 -MSE: 7.48497090364643 -Train Accuracy: 0.8666667\n",
      "epoch: 886 - cost: 0.2914913 -MSE: 7.4566963191427025 -Train Accuracy: 0.8848485\n",
      "epoch: 887 - cost: 0.29211572 -MSE: 7.486991672171679 -Train Accuracy: 0.8666667\n",
      "epoch: 888 - cost: 0.29077947 -MSE: 7.458918348444312 -Train Accuracy: 0.8848485\n",
      "epoch: 889 - cost: 0.2913778 -MSE: 7.489020095625966 -Train Accuracy: 0.8666667\n",
      "epoch: 890 - cost: 0.2900678 -MSE: 7.461149102638755 -Train Accuracy: 0.8848485\n",
      "epoch: 891 - cost: 0.2906403 -MSE: 7.4910527614762 -Train Accuracy: 0.8666667\n",
      "epoch: 892 - cost: 0.28935635 -MSE: 7.463389328305903 -Train Accuracy: 0.8848485\n",
      "epoch: 893 - cost: 0.28990325 -MSE: 7.493093003812929 -Train Accuracy: 0.8666667\n",
      "epoch: 894 - cost: 0.288645 -MSE: 7.465636087445957 -Train Accuracy: 0.8848485\n",
      "epoch: 895 - cost: 0.28916636 -MSE: 7.495138359842291 -Train Accuracy: 0.8727273\n",
      "epoch: 896 - cost: 0.28793374 -MSE: 7.467894349338017 -Train Accuracy: 0.8848485\n",
      "epoch: 897 - cost: 0.28843004 -MSE: 7.49718981702636 -Train Accuracy: 0.8727273\n",
      "epoch: 898 - cost: 0.28722268 -MSE: 7.470161088581411 -Train Accuracy: 0.8848485\n",
      "epoch: 899 - cost: 0.28769395 -MSE: 7.499247150254833 -Train Accuracy: 0.8727273\n",
      "epoch: 900 - cost: 0.2865117 -MSE: 7.472437918035693 -Train Accuracy: 0.8848485\n",
      "epoch: 901 - cost: 0.28695828 -MSE: 7.501310674966985 -Train Accuracy: 0.8727273\n",
      "epoch: 902 - cost: 0.28580078 -MSE: 7.474721035296979 -Train Accuracy: 0.8848485\n",
      "epoch: 903 - cost: 0.28622276 -MSE: 7.503379645004078 -Train Accuracy: 0.8727273\n",
      "epoch: 904 - cost: 0.2850899 -MSE: 7.477014071429448 -Train Accuracy: 0.8848485\n",
      "epoch: 905 - cost: 0.2854876 -MSE: 7.505452578134586 -Train Accuracy: 0.8727273\n",
      "epoch: 906 - cost: 0.28437904 -MSE: 7.479313445804737 -Train Accuracy: 0.8848485\n",
      "epoch: 907 - cost: 0.28475282 -MSE: 7.507529829924579 -Train Accuracy: 0.8727273\n",
      "epoch: 908 - cost: 0.28366828 -MSE: 7.481622635236931 -Train Accuracy: 0.8848485\n",
      "epoch: 909 - cost: 0.28401816 -MSE: 7.5096142280596165 -Train Accuracy: 0.8727273\n",
      "epoch: 910 - cost: 0.28295755 -MSE: 7.4839388003090255 -Train Accuracy: 0.8848485\n",
      "epoch: 911 - cost: 0.2832838 -MSE: 7.511702224650664 -Train Accuracy: 0.8727273\n",
      "epoch: 912 - cost: 0.28224674 -MSE: 7.48626402912924 -Train Accuracy: 0.8848485\n",
      "epoch: 913 - cost: 0.28254962 -MSE: 7.513794592580583 -Train Accuracy: 0.8727273\n",
      "epoch: 914 - cost: 0.28153598 -MSE: 7.488595631414512 -Train Accuracy: 0.8848485\n",
      "epoch: 915 - cost: 0.28181562 -MSE: 7.515892436287683 -Train Accuracy: 0.8727273\n",
      "epoch: 916 - cost: 0.28082517 -MSE: 7.490934895800895 -Train Accuracy: 0.8848485\n",
      "epoch: 917 - cost: 0.28108183 -MSE: 7.517995074038059 -Train Accuracy: 0.8727273\n",
      "epoch: 918 - cost: 0.28011438 -MSE: 7.493282439215581 -Train Accuracy: 0.8848485\n",
      "epoch: 919 - cost: 0.28034833 -MSE: 7.520099786122126 -Train Accuracy: 0.8727273\n",
      "epoch: 920 - cost: 0.27940348 -MSE: 7.495636490433439 -Train Accuracy: 0.8848485\n",
      "epoch: 921 - cost: 0.2796148 -MSE: 7.52220976538761 -Train Accuracy: 0.8727273\n",
      "epoch: 922 - cost: 0.27869254 -MSE: 7.4979993785794985 -Train Accuracy: 0.8848485\n",
      "epoch: 923 - cost: 0.27888167 -MSE: 7.524326485999173 -Train Accuracy: 0.8727273\n",
      "epoch: 924 - cost: 0.2779817 -MSE: 7.500370398825523 -Train Accuracy: 0.8848485\n",
      "epoch: 925 - cost: 0.2781486 -MSE: 7.526445514923997 -Train Accuracy: 0.8727273\n",
      "epoch: 926 - cost: 0.27727067 -MSE: 7.5027480729605065 -Train Accuracy: 0.8848485\n",
      "epoch: 927 - cost: 0.27741563 -MSE: 7.528568585224468 -Train Accuracy: 0.8727273\n",
      "epoch: 928 - cost: 0.27655953 -MSE: 7.505132677270426 -Train Accuracy: 0.8848485\n",
      "epoch: 929 - cost: 0.27668273 -MSE: 7.530695590769284 -Train Accuracy: 0.8727273\n",
      "epoch: 930 - cost: 0.27584833 -MSE: 7.507525696613548 -Train Accuracy: 0.8848485\n",
      "epoch: 931 - cost: 0.2759501 -MSE: 7.532827874586484 -Train Accuracy: 0.8727273\n",
      "epoch: 932 - cost: 0.27513716 -MSE: 7.509925241556307 -Train Accuracy: 0.8848485\n",
      "epoch: 933 - cost: 0.27521762 -MSE: 7.534965150778817 -Train Accuracy: 0.8727273\n",
      "epoch: 934 - cost: 0.2744258 -MSE: 7.512331057733969 -Train Accuracy: 0.8848485\n",
      "epoch: 935 - cost: 0.27448517 -MSE: 7.537103566613677 -Train Accuracy: 0.8727273\n",
      "epoch: 936 - cost: 0.2737144 -MSE: 7.514745337769679 -Train Accuracy: 0.8848485\n",
      "epoch: 937 - cost: 0.27375287 -MSE: 7.539246168439898 -Train Accuracy: 0.8727273\n",
      "epoch: 938 - cost: 0.27300292 -MSE: 7.5171652052446705 -Train Accuracy: 0.8969697\n",
      "epoch: 939 - cost: 0.27302065 -MSE: 7.541393788895583 -Train Accuracy: 0.8727273\n",
      "epoch: 940 - cost: 0.27229124 -MSE: 7.519593674151801 -Train Accuracy: 0.8969697\n",
      "epoch: 941 - cost: 0.27228844 -MSE: 7.543544838689651 -Train Accuracy: 0.8727273\n",
      "epoch: 942 - cost: 0.2715794 -MSE: 7.522027921503293 -Train Accuracy: 0.8969697\n",
      "epoch: 943 - cost: 0.27155644 -MSE: 7.545700085805812 -Train Accuracy: 0.8727273\n",
      "epoch: 944 - cost: 0.27086768 -MSE: 7.52446955201789 -Train Accuracy: 0.8969697\n",
      "epoch: 945 - cost: 0.27082446 -MSE: 7.547858956799013 -Train Accuracy: 0.8787879\n",
      "epoch: 946 - cost: 0.2701556 -MSE: 7.526919049579192 -Train Accuracy: 0.8969697\n",
      "epoch: 947 - cost: 0.27009243 -MSE: 7.550020916016727 -Train Accuracy: 0.8787879\n",
      "epoch: 948 - cost: 0.26944333 -MSE: 7.5293735134986 -Train Accuracy: 0.8969697\n",
      "epoch: 949 - cost: 0.26936063 -MSE: 7.552187593824845 -Train Accuracy: 0.8787879\n",
      "epoch: 950 - cost: 0.2687311 -MSE: 7.531835242925295 -Train Accuracy: 0.8969697\n",
      "epoch: 951 - cost: 0.26862887 -MSE: 7.554355158854641 -Train Accuracy: 0.8787879\n",
      "epoch: 952 - cost: 0.26801857 -MSE: 7.534303293515696 -Train Accuracy: 0.8969697\n",
      "epoch: 953 - cost: 0.2678971 -MSE: 7.556528230440778 -Train Accuracy: 0.8787879\n",
      "epoch: 954 - cost: 0.26730588 -MSE: 7.536777674766095 -Train Accuracy: 0.8969697\n",
      "epoch: 955 - cost: 0.26716518 -MSE: 7.558704779547419 -Train Accuracy: 0.8787879\n",
      "epoch: 956 - cost: 0.26659286 -MSE: 7.539258794181814 -Train Accuracy: 0.8969697\n",
      "epoch: 957 - cost: 0.26643324 -MSE: 7.560884883239323 -Train Accuracy: 0.8787879\n",
      "epoch: 958 - cost: 0.2658797 -MSE: 7.541745171606359 -Train Accuracy: 0.8969697\n",
      "epoch: 959 - cost: 0.26570138 -MSE: 7.563066647563749 -Train Accuracy: 0.8787879\n",
      "epoch: 960 - cost: 0.26516637 -MSE: 7.544239728968274 -Train Accuracy: 0.8969697\n",
      "epoch: 961 - cost: 0.26496956 -MSE: 7.565250631325517 -Train Accuracy: 0.8787879\n",
      "epoch: 962 - cost: 0.26445276 -MSE: 7.546738152462635 -Train Accuracy: 0.8969697\n",
      "epoch: 963 - cost: 0.2642376 -MSE: 7.567440046594323 -Train Accuracy: 0.8848485\n",
      "epoch: 964 - cost: 0.26373893 -MSE: 7.549244531824589 -Train Accuracy: 0.8969697\n",
      "epoch: 965 - cost: 0.26350573 -MSE: 7.569632042077222 -Train Accuracy: 0.8848485\n",
      "epoch: 966 - cost: 0.26302496 -MSE: 7.551757431810689 -Train Accuracy: 0.8969697\n",
      "epoch: 967 - cost: 0.26277372 -MSE: 7.571827155706119 -Train Accuracy: 0.8848485\n",
      "epoch: 968 - cost: 0.2623106 -MSE: 7.55427529698238 -Train Accuracy: 0.8969697\n",
      "epoch: 969 - cost: 0.2620416 -MSE: 7.574024697063497 -Train Accuracy: 0.8848485\n",
      "epoch: 970 - cost: 0.261596 -MSE: 7.556799611123641 -Train Accuracy: 0.8969697\n",
      "epoch: 971 - cost: 0.2613095 -MSE: 7.576225611960429 -Train Accuracy: 0.8848485\n",
      "epoch: 972 - cost: 0.26088107 -MSE: 7.559328372880581 -Train Accuracy: 0.9030303\n",
      "epoch: 973 - cost: 0.2605772 -MSE: 7.578427917852854 -Train Accuracy: 0.8848485\n",
      "epoch: 974 - cost: 0.2601658 -MSE: 7.56186245485653 -Train Accuracy: 0.9030303\n",
      "epoch: 975 - cost: 0.25984472 -MSE: 7.5806322455415 -Train Accuracy: 0.8848485\n",
      "epoch: 976 - cost: 0.25945014 -MSE: 7.564401798754629 -Train Accuracy: 0.9030303\n",
      "epoch: 977 - cost: 0.25911212 -MSE: 7.582839179882602 -Train Accuracy: 0.8848485\n",
      "epoch: 978 - cost: 0.25873423 -MSE: 7.566947545818356 -Train Accuracy: 0.9030303\n",
      "epoch: 979 - cost: 0.25837943 -MSE: 7.585050230892832 -Train Accuracy: 0.8848485\n",
      "epoch: 980 - cost: 0.25801805 -MSE: 7.569499804501752 -Train Accuracy: 0.9030303\n",
      "epoch: 981 - cost: 0.25764668 -MSE: 7.587263599970751 -Train Accuracy: 0.8848485\n",
      "epoch: 982 - cost: 0.2573015 -MSE: 7.572057187082678 -Train Accuracy: 0.9030303\n",
      "epoch: 983 - cost: 0.25691384 -MSE: 7.589479855193198 -Train Accuracy: 0.8848485\n",
      "epoch: 984 - cost: 0.25658464 -MSE: 7.574618561522364 -Train Accuracy: 0.9030303\n",
      "epoch: 985 - cost: 0.25618067 -MSE: 7.591697751860877 -Train Accuracy: 0.8848485\n",
      "epoch: 986 - cost: 0.25586724 -MSE: 7.577185676629333 -Train Accuracy: 0.9030303\n",
      "epoch: 987 - cost: 0.2554473 -MSE: 7.593917101165085 -Train Accuracy: 0.8848485\n",
      "epoch: 988 - cost: 0.2551495 -MSE: 7.5797578948155735 -Train Accuracy: 0.9030303\n",
      "epoch: 989 - cost: 0.25471377 -MSE: 7.596138989932721 -Train Accuracy: 0.8848485\n",
      "epoch: 990 - cost: 0.25443137 -MSE: 7.582335855449109 -Train Accuracy: 0.90909094\n",
      "epoch: 991 - cost: 0.25397995 -MSE: 7.59836477739276 -Train Accuracy: 0.8848485\n",
      "epoch: 992 - cost: 0.25371268 -MSE: 7.584918587403114 -Train Accuracy: 0.90909094\n",
      "epoch: 993 - cost: 0.25324592 -MSE: 7.600590764920508 -Train Accuracy: 0.8848485\n",
      "epoch: 994 - cost: 0.2529937 -MSE: 7.587506042416653 -Train Accuracy: 0.90909094\n",
      "epoch: 995 - cost: 0.25251168 -MSE: 7.602821136073671 -Train Accuracy: 0.8848485\n",
      "epoch: 996 - cost: 0.25227425 -MSE: 7.590099028341339 -Train Accuracy: 0.90909094\n",
      "epoch: 997 - cost: 0.25177723 -MSE: 7.605052674940301 -Train Accuracy: 0.8848485\n",
      "epoch: 998 - cost: 0.25155434 -MSE: 7.592696165543275 -Train Accuracy: 0.90909094\n",
      "epoch: 999 - cost: 0.2510425 -MSE: 7.607284494671719 -Train Accuracy: 0.8848485\n",
      "Model saved in file: C:\\Users\\hp\\Desktop\\dl\n"
     ]
    }
   ],
   "source": [
    "mse_history=[]\n",
    "accuracy_history=[]\n",
    "\n",
    "for epoch in range(training_epochs):\n",
    "    sess.run(training_step,feed_dict={x:train_x,y_:train_y})\n",
    "    cost=sess.run(cost_function,feed_dict={x:train_x,y_:train_y})\n",
    "    cost_history=np.append(cost_history,cost)\n",
    "    correct_prediction=tf.equal(tf.argmax(y,1),tf.argmax(y_,1))\n",
    "    accuracy=tf.reduce_mean(tf.cast(correct_prediction,tf.float32))\n",
    "    \n",
    "    #print accuracy\n",
    "    \n",
    "    pred_y=sess.run(y,feed_dict={x:test_x})\n",
    "    mse=tf.reduce_mean(tf.square(pred_y-test_y))\n",
    "    \n",
    "    mse_=sess.run(mse)\n",
    "    mse_history.append(mse_)\n",
    "    accuracy=(sess.run(accuracy,feed_dict={x:train_x,y_:train_y}))\n",
    "    accuracy_history.append(accuracy)\n",
    "    \n",
    "    print('epoch:',epoch,'-','cost:',cost,\"-MSE:\",mse_,\"-Train Accuracy:\",accuracy)\n",
    "    \n",
    "save_path=saver.save(sess,model_path)\n",
    "print(\"Model saved in file: %s\" % save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Plot mse and accuracy graph\n",
    "plt.plot(mse_history,'r')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(accuracy_history)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# # print the final accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.8333333\n"
     ]
    }
   ],
   "source": [
    "correct_prediction=tf.equal(tf.argmax(y,1),tf.argmax(y_,1))\n",
    "accuracy=tf.reduce_mean(tf.cast(correct_prediction,tf.float32))\n",
    "print(\"Test Accuracy:\",(sess.run(accuracy,feed_dict={x:test_x,y_:test_y})))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# #print the final mean square error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE:7.6073\n"
     ]
    }
   ],
   "source": [
    "pred_y=sess.run(y,feed_dict={x:test_x})\n",
    "mse=tf.reduce_mean(tf.square(pred_y-test_y))\n",
    "print(\"MSE:%.4f\" % sess.run(mse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction=tf.argmax(y,1)\n",
    "correct_prediction=tf.equal(prediction,tf.argmax(y_,1))\n",
    "accuracy=tf.reduce_mean(tf.cast(correct_prediction,tf.float32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# #print accuracy run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******************************\n",
      "0 stands for M i.e. Mine and 1 stands for R i.e. Rock\n",
      "******************************\n",
      "2 Original Class:  0  Predicted Values:  0\n",
      "Accuracy:  100.0%\n",
      "3 Original Class:  0  Predicted Values:  0\n",
      "Accuracy:  100.0%\n",
      "4 Original Class:  1  Predicted Values:  1\n",
      "Accuracy:  100.0%\n",
      "5 Original Class:  1  Predicted Values:  1\n",
      "Accuracy:  100.0%\n",
      "6 Original Class:  0  Predicted Values:  0\n",
      "Accuracy:  100.0%\n",
      "7 Original Class:  1  Predicted Values:  0\n",
      "Accuracy:  0.0%\n",
      "8 Original Class:  0  Predicted Values:  0\n",
      "Accuracy:  100.0%\n",
      "9 Original Class:  1  Predicted Values:  1\n",
      "Accuracy:  100.0%\n",
      "10 Original Class:  1  Predicted Values:  1\n",
      "Accuracy:  100.0%\n",
      "11 Original Class:  1  Predicted Values:  1\n",
      "Accuracy:  100.0%\n"
     ]
    }
   ],
   "source": [
    "print('******************************')\n",
    "print(\"0 stands for M i.e. Mine and 1 stands for R i.e. Rock\")\n",
    "print('******************************')\n",
    "\n",
    "for i in range(2,12):\n",
    "    \n",
    "    prediction_run = sess.run(prediction, feed_dict={x:X[i].reshape(1,60)})\n",
    "    accuracy_run = sess.run(accuracy, feed_dict={x:X[i].reshape(1,60), y_:Y[i].reshape(1,2)})\n",
    "    print(i,\"Original Class: \", int(sess.run(y_[i][1],feed_dict={y_:Y})), \" Predicted Values: \", prediction_run[0] )\n",
    "    print(\"Accuracy: \",str(accuracy_run*100)+\"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
